{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from normalizer import subSample, getDataFromJSON, trainer, getTotalAccuracy, tester, cfvalidation\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # Change this to cuda for GPU enabled computers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition1_data.json\n",
      "Now loading event 1/785\n",
      "Now loading event 101/785\n",
      "Now loading event 201/785\n",
      "Now loading event 301/785\n",
      "Now loading event 401/785\n",
      "Now loading event 501/785\n",
      "Now loading event 601/785\n",
      "Now loading event 701/785\n",
      "785 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "# This file has 77270 data points. 71633 do not have NAN values.\n",
    "# %time train1, labels1, weights1 = getDataFromJSON(path=\"data/train_partition1_data.json\", earlyStop=-1)\n",
    "train1, labels1 = subSample(\"data/train_partition1_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition2_data.json\n",
      "Now loading event 1/300\n",
      "Now loading event 101/300\n",
      "Now loading event 201/300\n",
      "300 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "# This file has 93767 data points. 82425 of them do not have NAN values.  \n",
    "# %time train2, labels2, weights2 = getDataFromJSON(path=\"data/train_partition2_data.json\", earlyStop=-1)\n",
    "train2, labels2 = subSample(\"data/train_partition2_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition3_data.json\n",
      "Now loading event 1/585\n",
      "Now loading event 101/585\n",
      "Now loading event 201/585\n",
      "Now loading event 301/585\n",
      "Now loading event 401/585\n",
      "Now loading event 501/585\n",
      "585 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "# This file has 42986 data points. 37759 of them do not have NAN values.  \n",
    "# %time train3, labels3, weights3 = getDataFromJSON(path=\"data/train_partition3_data.json\", earlyStop=-1)\n",
    "train3, labels3 = subSample(\"data/train_partition3_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0693, 0.0694, 0.0694, 0.0696, 0.0693, 0.0697, 0.0696, 0.0689, 0.0690,\n",
       "        0.0689, 0.0688, 0.0685, 0.0689, 0.0692, 0.0696, 0.0696, 0.0695, 0.0693,\n",
       "        0.0693, 0.0688, 0.0680, 0.0671, 0.0669, 0.0667, 0.0663, 0.0664, 0.0664,\n",
       "        0.0666, 0.0659, 0.0657, 0.0651, 0.0649, 0.0650, 0.0663, 0.0667, 0.0668,\n",
       "        0.0670, 0.0674, 0.0678, 0.0681, 0.0678, 0.0678, 0.0679, 0.0680, 0.0682,\n",
       "        0.0684, 0.0690, 0.0689, 0.0689, 0.0693, 0.0691, 0.0692, 0.0697, 0.0699,\n",
       "        0.0698, 0.0699, 0.0700, 0.0698, 0.0694, 0.0692])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0979, 0.0984, 0.0984, 0.0984, 0.0979, 0.1002, 0.1009, 0.0993, 0.0991,\n",
       "        0.0988, 0.0982, 0.0994, 0.0994, 0.1009, 0.0996, 0.0983, 0.0981, 0.0979,\n",
       "        0.0981, 0.0959, 0.0930, 0.0925, 0.0933, 0.0921, 0.0917, 0.0936, 0.0929,\n",
       "        0.0957, 0.0949, 0.0963, 0.0969, 0.0948, 0.0961, 0.1017, 0.1055, 0.1060,\n",
       "        0.1081, 0.1079, 0.1068, 0.1091, 0.1102, 0.1115, 0.1105, 0.1104, 0.1104,\n",
       "        0.1123, 0.1163, 0.1141, 0.1147, 0.1149, 0.1135, 0.1131, 0.1144, 0.1126,\n",
       "        0.1127, 0.1134, 0.1130, 0.1128, 0.1103, 0.1084])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network. Make sure to end with nn.Softmax activation\n",
    "import torch.nn as nn\n",
    "# from skorch import NeuralNet\n",
    "\n",
    "class logRegWithHidden(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, num_classes=5, drop1=.5, input_size=1980):\n",
    "        super().__init__() \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layerout = nn.Linear(hidden_size2, num_classes)\n",
    "        #Define a RELU Activation unit\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.smax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(p=drop1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Forward Propagate through the layers as defined above\n",
    "        y = self.drop(x.reshape(-1, 1980))\n",
    "        y = self.drop(self.relu(self.layer1(y)))\n",
    "        y = self.relu(self.layer2(y))\n",
    "        y = self.layerout(y)\n",
    "        y = self.smax(y)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [4096*4,4096,1024]\n",
    "hls = [4096*2, 2048, 512]\n",
    "margs = []\n",
    "for n in ns:\n",
    "    for h in hls:\n",
    "        margs.append([n,h])\n",
    "lrs = [10**i for i in range(0,-5, -1)]\n",
    "drs = [0, .17, .32, .5]\n",
    "tripList = []\n",
    "for ma in margs:\n",
    "    for r in lrs:\n",
    "        for d in drs:\n",
    "            tripList.append([ma, {'drop1': d}, r])\n",
    "lossArgs, quickArgs = cfvalidation(tripList, CNNinspired, train1, labels1, train2, labels2, train3, labels3, 200)\n",
    "print(lossArgs, quickArgs, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust hyper parameters with 3 fold validation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelArgs = [4096*4, 2048*4]\n",
    "modelKwargs = {'drop1':.25}\n",
    "trainKwargs = {'epochs':50, 'lr':0.0001}\n",
    "# Attempted learning rates: \n",
    "# 0.0001 : one in a thousand change\n",
    "# 0.00001 : one in TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/50 was 1.6095042088452507\n",
      "The total balanced accuracy for validation was 0.2341880341880342\n",
      "The validation loss was :   1/50 was 1.6090488236174625\n",
      "The unbalanced validation accuracy is 0.2341880341880342\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.17094017094017094, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 2/50 was 1.609286623842576\n",
      "The total balanced accuracy for validation was 0.23247863247863249\n",
      "The validation loss was :   2/50 was 1.6089208731284508\n",
      "The unbalanced validation accuracy is 0.23247863247863249\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.1623931623931624, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 3/50 was 1.6093182844274185\n",
      "The total balanced accuracy for validation was 0.22905982905982905\n",
      "The validation loss was :   3/50 was 1.6087923003058149\n",
      "The unbalanced validation accuracy is 0.22905982905982905\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.1452991452991453, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 4/50 was 1.609229235088124\n",
      "The total balanced accuracy for validation was 0.22735042735042735\n",
      "The validation loss was :   4/50 was 1.608664463320349\n",
      "The unbalanced validation accuracy is 0.22735042735042735\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.13675213675213677, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 5/50 was 1.6086225439520443\n",
      "The total balanced accuracy for validation was 0.22051282051282053\n",
      "The validation loss was :   5/50 was 1.6085358719540457\n",
      "The unbalanced validation accuracy is 0.2205128205128205\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.10256410256410256, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 6/50 was 1.6089143262189978\n",
      "The total balanced accuracy for validation was 0.21880341880341883\n",
      "The validation loss was :   6/50 was 1.6084083685508141\n",
      "The unbalanced validation accuracy is 0.2188034188034188\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.09401709401709402, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 7/50 was 1.6087145174250883\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   7/50 was 1.6082815098966288\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 8/50 was 1.6082580580430872\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   8/50 was 1.6081551081094987\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 9/50 was 1.6084783778471106\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   9/50 was 1.6080286998015183\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 10/50 was 1.6082381150301766\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   10/50 was 1.6079027662929306\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 11/50 was 1.6081462677787333\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   11/50 was 1.6077772823154417\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 12/50 was 1.608229209395016\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   12/50 was 1.607651880867461\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 13/50 was 1.6078615819706636\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   13/50 was 1.6075262628049931\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 14/50 was 1.607709849581999\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   14/50 was 1.6074020522272485\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 15/50 was 1.6077415031545303\n",
      "The total balanced accuracy for validation was 0.21538461538461537\n",
      "The validation loss was :   15/50 was 1.6072772103497106\n",
      "The unbalanced validation accuracy is 0.2153846153846154\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.07692307692307693, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 16/50 was 1.607611522955053\n",
      "The total balanced accuracy for validation was 0.21538461538461537\n",
      "The validation loss was :   16/50 was 1.6071533914305205\n",
      "The unbalanced validation accuracy is 0.2153846153846154\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.07692307692307693, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 17/50 was 1.6078453554826624\n",
      "The total balanced accuracy for validation was 0.21538461538461537\n",
      "The validation loss was :   17/50 was 1.6070300793036436\n",
      "The unbalanced validation accuracy is 0.2153846153846154\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.07692307692307693, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 18/50 was 1.6072598345139448\n",
      "The total balanced accuracy for validation was 0.21367521367521367\n",
      "The validation loss was :   18/50 was 1.6069064564175075\n",
      "The unbalanced validation accuracy is 0.21367521367521367\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.06837606837606838, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 19/50 was 1.6073427621056051\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   19/50 was 1.6067821653480203\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 20/50 was 1.6072734804714428\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   20/50 was 1.6066587197474944\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 21/50 was 1.6074452470330631\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   21/50 was 1.6065362736710116\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 22/50 was 1.6068792202893425\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   22/50 was 1.6064133208022158\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 23/50 was 1.6067823241738712\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   23/50 was 1.6062909393229037\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 24/50 was 1.6067255875643562\n",
      "The total balanced accuracy for validation was 0.21025641025641026\n",
      "The validation loss was :   24/50 was 1.6061693436060196\n",
      "The unbalanced validation accuracy is 0.21025641025641026\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05128205128205128, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 25/50 was 1.6065998778623694\n",
      "The total balanced accuracy for validation was 0.21025641025641026\n",
      "The validation loss was :   25/50 was 1.6060477026507385\n",
      "The unbalanced validation accuracy is 0.21025641025641026\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05128205128205128, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 26/50 was 1.6062607484705307\n",
      "The total balanced accuracy for validation was 0.21025641025641026\n",
      "The validation loss was :   26/50 was 1.6059265540196346\n",
      "The unbalanced validation accuracy is 0.21025641025641026\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05128205128205128, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 27/50 was 1.606649917714736\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   27/50 was 1.605805867146223\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 28/50 was 1.6061673865598791\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   28/50 was 1.6056839099297158\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 29/50 was 1.6060215304879581\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   29/50 was 1.6055622139547625\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 30/50 was 1.605934739112854\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   30/50 was 1.6054416931592501\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 31/50 was 1.6057410310296452\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   31/50 was 1.6053211609522502\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 32/50 was 1.6058657730326933\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   32/50 was 1.6052006766327427\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 33/50 was 1.605603246127858\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   33/50 was 1.6050802793258276\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 34/50 was 1.6052868857103235\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   34/50 was 1.6049596419701209\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 35/50 was 1.605758176130407\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   35/50 was 1.6048396247064964\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 36/50 was 1.6051752847783707\n",
      "The total balanced accuracy for validation was 0.20683760683760685\n",
      "The validation loss was :   36/50 was 1.6047199885050456\n",
      "The unbalanced validation accuracy is 0.20683760683760682\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.03418803418803419, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 37/50 was 1.6051467867458569\n",
      "The total balanced accuracy for validation was 0.20683760683760685\n",
      "The validation loss was :   37/50 was 1.6045994648566613\n",
      "The unbalanced validation accuracy is 0.20683760683760682\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.03418803418803419, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 38/50 was 1.605280224014731\n",
      "The total balanced accuracy for validation was 0.20683760683760685\n",
      "The validation loss was :   38/50 was 1.6044800244844877\n",
      "The unbalanced validation accuracy is 0.20683760683760682\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.03418803418803419, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 39/50 was 1.6051014802035164\n",
      "The total balanced accuracy for validation was 0.20683760683760685\n",
      "The validation loss was :   39/50 was 1.604361602791354\n",
      "The unbalanced validation accuracy is 0.20683760683760682\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.03418803418803419, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 40/50 was 1.6048879483166862\n",
      "The total balanced accuracy for validation was 0.20683760683760685\n",
      "The validation loss was :   40/50 was 1.604242094561585\n",
      "The unbalanced validation accuracy is 0.20683760683760682\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.03418803418803419, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 41/50 was 1.6047023815267227\n",
      "The total balanced accuracy for validation was 0.20683760683760685\n",
      "The validation loss was :   41/50 was 1.6041244543515718\n",
      "The unbalanced validation accuracy is 0.20683760683760682\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.03418803418803419, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 42/50 was 1.604705305660472\n",
      "The total balanced accuracy for validation was 0.20683760683760685\n",
      "The validation loss was :   42/50 was 1.6040062863602598\n",
      "The unbalanced validation accuracy is 0.20683760683760682\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.03418803418803419, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 43/50 was 1.6045372696483837\n",
      "The total balanced accuracy for validation was 0.20683760683760685\n",
      "The validation loss was :   43/50 was 1.6038876670038598\n",
      "The unbalanced validation accuracy is 0.20683760683760682\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.03418803418803419, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 44/50 was 1.6046600902781767\n",
      "The total balanced accuracy for validation was 0.20683760683760685\n",
      "The validation loss was :   44/50 was 1.6037707552950606\n",
      "The unbalanced validation accuracy is 0.20683760683760682\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.03418803418803419, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 45/50 was 1.6040296975304098\n",
      "The total balanced accuracy for validation was 0.20512820512820512\n",
      "The validation loss was :   45/50 was 1.6036523739496866\n",
      "The unbalanced validation accuracy is 0.20512820512820512\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.02564102564102564, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 46/50 was 1.6042615736232084\n",
      "The total balanced accuracy for validation was 0.20512820512820512\n",
      "The validation loss was :   46/50 was 1.60353496400719\n",
      "The unbalanced validation accuracy is 0.20512820512820512\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.02564102564102564, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 47/50 was 1.6041883300332462\n",
      "The total balanced accuracy for validation was 0.20512820512820512\n",
      "The validation loss was :   47/50 was 1.6034181014085427\n",
      "The unbalanced validation accuracy is 0.20512820512820512\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.02564102564102564, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 48/50 was 1.6041658345390768\n",
      "The total balanced accuracy for validation was 0.20341880341880342\n",
      "The validation loss was :   48/50 was 1.6033001706131502\n",
      "The unbalanced validation accuracy is 0.20341880341880342\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.017094017094017096, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 49/50 was 1.6039717828526217\n",
      "The total balanced accuracy for validation was 0.20341880341880342\n",
      "The validation loss was :   49/50 was 1.6031824723268167\n",
      "The unbalanced validation accuracy is 0.20341880341880342\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.017094017094017096, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 50/50 was 1.603757711017833\n",
      "The total balanced accuracy for validation was 0.20341880341880342\n",
      "The validation loss was :   50/50 was 1.603064218749348\n",
      "The unbalanced validation accuracy is 0.20341880341880342\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.017094017094017096, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 5min 34s, sys: 5min 41s, total: 1h 11min 16s\n",
      "Wall time: 18min 13s\n"
     ]
    }
   ],
   "source": [
    "train1Args = [logRegWithHidden, torch.cat((train1, train2), dim=0), labels1 + labels2, None, train3, labels3, None]\n",
    "%time train12 = trainer(*train1Args, *modelArgs, **trainKwargs, **modelKwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/50 was 1.6096194819970564\n",
      "The total balanced accuracy for validation was 0.36\n",
      "The validation loss was :   1/50 was 1.6082851068178812\n",
      "The unbalanced validation accuracy is 0.36\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.8]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 2/50 was 1.6091773022304883\n",
      "The total balanced accuracy for validation was 0.36\n",
      "The validation loss was :   2/50 was 1.6081017128626505\n",
      "The unbalanced validation accuracy is 0.36\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.8]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 3/50 was 1.6091259934685447\n",
      "The total balanced accuracy for validation was 0.35666666666666663\n",
      "The validation loss was :   3/50 was 1.6079191001256308\n",
      "The unbalanced validation accuracy is 0.3566666666666667\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.7833333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 4/50 was 1.6086100177331404\n",
      "The total balanced accuracy for validation was 0.3466666666666667\n",
      "The validation loss was :   4/50 was 1.6077354013919831\n",
      "The unbalanced validation accuracy is 0.3466666666666667\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.7333333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 5/50 was 1.6088217063383623\n",
      "The total balanced accuracy for validation was 0.33999999999999997\n",
      "The validation loss was :   5/50 was 1.6075540089607239\n",
      "The unbalanced validation accuracy is 0.34\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.7]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 6/50 was 1.6078819253227927\n",
      "The total balanced accuracy for validation was 0.32999999999999996\n",
      "The validation loss was :   6/50 was 1.6073716859022775\n",
      "The unbalanced validation accuracy is 0.33\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.65]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 7/50 was 1.6081800785931675\n",
      "The total balanced accuracy for validation was 0.32\n",
      "The validation loss was :   7/50 was 1.6071915284792582\n",
      "The unbalanced validation accuracy is 0.32\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.6]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 8/50 was 1.6081645326180891\n",
      "The total balanced accuracy for validation was 0.31333333333333335\n",
      "The validation loss was :   8/50 was 1.6070123533407847\n",
      "The unbalanced validation accuracy is 0.31333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.5666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 9/50 was 1.6083867333152078\n",
      "The total balanced accuracy for validation was 0.31333333333333335\n",
      "The validation loss was :   9/50 was 1.6068324677149455\n",
      "The unbalanced validation accuracy is 0.31333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.5666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 10/50 was 1.6079284928061746\n",
      "The total balanced accuracy for validation was 0.31333333333333335\n",
      "The validation loss was :   10/50 was 1.606653033097585\n",
      "The unbalanced validation accuracy is 0.31333333333333335\n",
      "The accuracy for each is [1.0, 0.016666666666666666, 0.0, 0.0, 0.55]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 11/50 was 1.607949885455045\n",
      "The total balanced accuracy for validation was 0.2866666666666667\n",
      "The validation loss was :   11/50 was 1.6064758916695914\n",
      "The unbalanced validation accuracy is 0.2866666666666667\n",
      "The accuracy for each is [1.0, 0.016666666666666666, 0.0, 0.0, 0.4166666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 12/50 was 1.60739296132868\n",
      "The total balanced accuracy for validation was 0.27999999999999997\n",
      "The validation loss was :   12/50 was 1.6062979598840077\n",
      "The unbalanced validation accuracy is 0.28\n",
      "The accuracy for each is [1.0, 0.016666666666666666, 0.0, 0.0, 0.38333333333333336]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 13/50 was 1.6075634089383213\n",
      "The total balanced accuracy for validation was 0.2733333333333333\n",
      "The validation loss was :   13/50 was 1.6061214510599773\n",
      "The unbalanced validation accuracy is 0.2733333333333333\n",
      "The accuracy for each is [1.0, 0.016666666666666666, 0.0, 0.0, 0.35]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 14/50 was 1.6073979518630288\n",
      "The total balanced accuracy for validation was 0.2633333333333333\n",
      "The validation loss was :   14/50 was 1.6059441045920053\n",
      "The unbalanced validation accuracy is 0.2633333333333333\n",
      "The accuracy for each is [1.0, 0.016666666666666666, 0.0, 0.0, 0.3]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 15/50 was 1.6069445989348672\n",
      "The total balanced accuracy for validation was 0.2533333333333333\n",
      "The validation loss was :   15/50 was 1.6057681035995484\n",
      "The unbalanced validation accuracy is 0.25333333333333335\n",
      "The accuracy for each is [1.0, 0.016666666666666666, 0.0, 0.0, 0.25]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 16/50 was 1.6072132099758496\n",
      "The total balanced accuracy for validation was 0.25\n",
      "The validation loss was :   16/50 was 1.6055927717685698\n",
      "The unbalanced validation accuracy is 0.25\n",
      "The accuracy for each is [1.0, 0.016666666666666666, 0.0, 0.0, 0.23333333333333334]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 17/50 was 1.606877326965332\n",
      "The total balanced accuracy for validation was 0.24333333333333335\n",
      "The validation loss was :   17/50 was 1.6054166861375172\n",
      "The unbalanced validation accuracy is 0.24333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.21666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 18/50 was 1.6066114469008013\n",
      "The total balanced accuracy for validation was 0.23666666666666666\n",
      "The validation loss was :   18/50 was 1.6052429533004762\n",
      "The unbalanced validation accuracy is 0.23666666666666666\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.18333333333333332]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 19/50 was 1.6063540577888489\n",
      "The total balanced accuracy for validation was 0.23666666666666666\n",
      "The validation loss was :   19/50 was 1.6050683482487997\n",
      "The unbalanced validation accuracy is 0.23666666666666666\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.18333333333333332]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 20/50 was 1.6063055937940425\n",
      "The total balanced accuracy for validation was 0.23666666666666666\n",
      "The validation loss was :   20/50 was 1.6048952702681223\n",
      "The unbalanced validation accuracy is 0.23666666666666666\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.18333333333333332]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 21/50 was 1.6060635555874219\n",
      "The total balanced accuracy for validation was 0.22999999999999998\n",
      "The validation loss was :   21/50 was 1.604721236228943\n",
      "The unbalanced validation accuracy is 0.23\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.15]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 22/50 was 1.605883170257915\n",
      "The total balanced accuracy for validation was 0.22666666666666666\n",
      "The validation loss was :   22/50 was 1.604549029270808\n",
      "The unbalanced validation accuracy is 0.22666666666666666\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.13333333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 23/50 was 1.6057114709507336\n",
      "The total balanced accuracy for validation was 0.22666666666666666\n",
      "The validation loss was :   23/50 was 1.6043761138121286\n",
      "The unbalanced validation accuracy is 0.22666666666666666\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.13333333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 24/50 was 1.6056050170551648\n",
      "The total balanced accuracy for validation was 0.22666666666666666\n",
      "The validation loss was :   24/50 was 1.60420295159022\n",
      "The unbalanced validation accuracy is 0.22666666666666666\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.13333333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 25/50 was 1.6054776039990513\n",
      "The total balanced accuracy for validation was 0.22333333333333333\n",
      "The validation loss was :   25/50 was 1.6040290252367655\n",
      "The unbalanced validation accuracy is 0.22333333333333333\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.11666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 26/50 was 1.6055082136934453\n",
      "The total balanced accuracy for validation was 0.22333333333333333\n",
      "The validation loss was :   26/50 was 1.6038569128513336\n",
      "The unbalanced validation accuracy is 0.22333333333333333\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.11666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 27/50 was 1.604989393190904\n",
      "The total balanced accuracy for validation was 0.22333333333333333\n",
      "The validation loss was :   27/50 was 1.6036853818098704\n",
      "The unbalanced validation accuracy is 0.22333333333333333\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.11666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 28/50 was 1.604903058572249\n",
      "The total balanced accuracy for validation was 0.22333333333333333\n",
      "The validation loss was :   28/50 was 1.6035139457384746\n",
      "The unbalanced validation accuracy is 0.22333333333333333\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.11666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 29/50 was 1.60504520481283\n",
      "The total balanced accuracy for validation was 0.22000000000000003\n",
      "The validation loss was :   29/50 was 1.6033430274327596\n",
      "The unbalanced validation accuracy is 0.22\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.1]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 30/50 was 1.6048351363702253\n",
      "The total balanced accuracy for validation was 0.22000000000000003\n",
      "The validation loss was :   30/50 was 1.603172463575999\n",
      "The unbalanced validation accuracy is 0.22\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.1]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 31/50 was 1.6046465960415928\n",
      "The total balanced accuracy for validation was 0.21666666666666665\n",
      "The validation loss was :   31/50 was 1.6030022132396697\n",
      "The unbalanced validation accuracy is 0.21666666666666667\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.08333333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 32/50 was 1.6043650995601306\n",
      "The total balanced accuracy for validation was 0.21666666666666665\n",
      "The validation loss was :   32/50 was 1.6028314169247946\n",
      "The unbalanced validation accuracy is 0.21666666666666667\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.08333333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 33/50 was 1.6038599610328674\n",
      "The total balanced accuracy for validation was 0.21666666666666665\n",
      "The validation loss was :   33/50 was 1.6026586699485779\n",
      "The unbalanced validation accuracy is 0.21666666666666667\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.08333333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 34/50 was 1.604182330044833\n",
      "The total balanced accuracy for validation was 0.21666666666666665\n",
      "The validation loss was :   34/50 was 1.6024892338116963\n",
      "The unbalanced validation accuracy is 0.21666666666666667\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.08333333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 35/50 was 1.6039285117929631\n",
      "The total balanced accuracy for validation was 0.21666666666666665\n",
      "The validation loss was :   35/50 was 1.6023194559415181\n",
      "The unbalanced validation accuracy is 0.21666666666666667\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.08333333333333333]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 36/50 was 1.6039685065096074\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   36/50 was 1.602149614095688\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 37/50 was 1.603811258619482\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   37/50 was 1.6019807358582814\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 38/50 was 1.6035613851113752\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   38/50 was 1.6018122204144796\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 39/50 was 1.603443438356573\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   39/50 was 1.6016428470611572\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 40/50 was 1.6032501459121704\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   40/50 was 1.6014727644125621\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 41/50 was 1.60338233275847\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   41/50 was 1.6013049817085265\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 42/50 was 1.6032319502397017\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   42/50 was 1.6011359612147014\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 43/50 was 1.6026841402053833\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   43/50 was 1.6009666947523753\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 44/50 was 1.6025310646403919\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   44/50 was 1.6008000222841898\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 45/50 was 1.6027354977347634\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   45/50 was 1.6006331169605255\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 46/50 was 1.6023080240596423\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   46/50 was 1.600466589530309\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 47/50 was 1.60241422328082\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   47/50 was 1.6002987575531007\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 48/50 was 1.6019184968688271\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   48/50 was 1.6001320354143778\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 49/50 was 1.602327135476199\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   49/50 was 1.599964700539907\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 50/50 was 1.6019977710463784\n",
      "The total balanced accuracy for validation was 0.21333333333333332\n",
      "The validation loss was :   50/50 was 1.5997963778177897\n",
      "The unbalanced validation accuracy is 0.21333333333333335\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.06666666666666667]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train13 = trainer(\n",
    "    logRegWithHidden,\n",
    "    torch.cat((train1, train3), dim=0),\n",
    "    labels1 + labels3,\n",
    "    None,\n",
    "    train2,\n",
    "    labels2,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/50 was 1.6094960570335388\n",
      "The total balanced accuracy for validation was 0.19872611464968154\n",
      "The validation loss was :   1/50 was 1.6089203113203596\n",
      "The unbalanced validation accuracy is 0.19872611464968154\n",
      "The accuracy for each is [0.0, 0.9936305732484076, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 2/50 was 1.6088675515992301\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   2/50 was 1.6088244922601493\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 3/50 was 1.6087413004466466\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   3/50 was 1.6087286168602621\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 4/50 was 1.6086211034229823\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   4/50 was 1.608632305776997\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 5/50 was 1.6083055819783891\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   5/50 was 1.6085360959836632\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 6/50 was 1.608380206993648\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   6/50 was 1.6084404491315223\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 7/50 was 1.6087179013660975\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   7/50 was 1.6083459237578568\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 8/50 was 1.608537197113037\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   8/50 was 1.6082519411281415\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 9/50 was 1.6079451867512293\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   9/50 was 1.608156933754113\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 10/50 was 1.6084226880754744\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   10/50 was 1.6080631316847103\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 11/50 was 1.607919258730752\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   11/50 was 1.607968558931047\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 12/50 was 1.6082463264465332\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   12/50 was 1.607874940307277\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 13/50 was 1.6079694628715515\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   13/50 was 1.607781528059844\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 14/50 was 1.6079219664846147\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   14/50 was 1.6076871156692505\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 15/50 was 1.6073709385735648\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   15/50 was 1.6075931828492767\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 16/50 was 1.6075873715536935\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   16/50 was 1.6074994937629457\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 17/50 was 1.6077406576701574\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   17/50 was 1.6074062418785824\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 18/50 was 1.607993985925402\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   18/50 was 1.6073131849811335\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 19/50 was 1.6075778007507324\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   19/50 was 1.6072208673331387\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 20/50 was 1.6074061053139823\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   20/50 was 1.6071280081560657\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 21/50 was 1.6073035427502222\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   21/50 was 1.6070357081237112\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 22/50 was 1.6074407952172416\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   22/50 was 1.6069439563022299\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 23/50 was 1.6068634050233024\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   23/50 was 1.6068511637912435\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 24/50 was 1.6071688107081823\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   24/50 was 1.6067597138653895\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 25/50 was 1.6068468604769026\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   25/50 was 1.606667418540663\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 26/50 was 1.6067232063838415\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   26/50 was 1.606576184102684\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 27/50 was 1.6066504120826721\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   27/50 was 1.6064851300731586\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 28/50 was 1.6066959670611791\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   28/50 was 1.6063932698243744\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 29/50 was 1.60647314786911\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   29/50 was 1.6063024435833002\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 30/50 was 1.6062114238739014\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   30/50 was 1.606210675664768\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 31/50 was 1.6066476276942663\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   31/50 was 1.6061199505617665\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 32/50 was 1.6060490608215332\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   32/50 was 1.6060289549979434\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 33/50 was 1.6065973469189234\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   33/50 was 1.605937712967016\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 34/50 was 1.6062866364206587\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   34/50 was 1.6058465936381345\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 35/50 was 1.6063953808375768\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   35/50 was 1.6057557145501398\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 36/50 was 1.6059681347438268\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   36/50 was 1.6056654561097454\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 37/50 was 1.6062143530164446\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   37/50 was 1.6055759516491253\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 38/50 was 1.6056440302303858\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   38/50 was 1.6054855782514925\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 39/50 was 1.605667872088296\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   39/50 was 1.6053951993869369\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 40/50 was 1.605382297720228\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   40/50 was 1.6053051199882653\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 41/50 was 1.6057177441460746\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   41/50 was 1.6052151534208068\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 42/50 was 1.6059047664914812\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   42/50 was 1.6051255798643562\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 43/50 was 1.605647657598768\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   43/50 was 1.6050362864877008\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 44/50 was 1.6056326031684875\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   44/50 was 1.6049470456542483\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 45/50 was 1.605362398283822\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   45/50 was 1.6048581577410364\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 46/50 was 1.6048407384327479\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   46/50 was 1.6047683371100456\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 47/50 was 1.6050207274300712\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   47/50 was 1.604679133633899\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 48/50 was 1.6049694929804121\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   48/50 was 1.604590115577552\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 49/50 was 1.604859275477273\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   49/50 was 1.6045004753550147\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 50/50 was 1.604935646057129\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   50/50 was 1.604411904978904\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train23 = trainer(\n",
    "    logRegWithHidden,\n",
    "    torch.cat((train3, train2), dim=0),\n",
    "    labels3 + labels2,\n",
    "    None,\n",
    "    train1,\n",
    "    labels1,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy of all three models on all data:  0.20139720558882235\n"
     ]
    }
   ],
   "source": [
    "acc = getTotalAccuracy(train12, train23, train13, \n",
    "                       torch.cat((train1, train2, train3), dim=0),\n",
    "                      labels1 + labels2 + labels3)\n",
    "print('Average accuracy of all three models on all data: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model creation for testing ##\n",
    "\n",
    "Once acceptable hyperparameters have been established, run this code to train on all the data and print out a CSV that predicts from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/50 was 1.6076555472833138\n",
      "The total balanced accuracy for validation was 0.24371257485029937\n",
      "The validation loss was :   1/50 was 1.6081288628235548\n",
      "The unbalanced validation accuracy is 0.2437125748502994\n",
      "The accuracy for each is [0.32335329341317365, 0.0, 0.8922155688622755, 0.0029940119760479044, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 2/50 was 1.6073362429936726\n",
      "The total balanced accuracy for validation was 0.25389221556886227\n",
      "The validation loss was :   2/50 was 1.6079272088890304\n",
      "The unbalanced validation accuracy is 0.25389221556886227\n",
      "The accuracy for each is [0.40119760479041916, 0.0, 0.8652694610778443, 0.0029940119760479044, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 3/50 was 1.6074187843887895\n",
      "The total balanced accuracy for validation was 0.29221556886227545\n",
      "The validation loss was :   3/50 was 1.6077276601762829\n",
      "The unbalanced validation accuracy is 0.29221556886227545\n",
      "The accuracy for each is [0.6437125748502994, 0.0, 0.8173652694610778, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 4/50 was 1.6072885151262637\n",
      "The total balanced accuracy for validation was 0.3017964071856287\n",
      "The validation loss was :   4/50 was 1.607527940858624\n",
      "The unbalanced validation accuracy is 0.3017964071856287\n",
      "The accuracy for each is [0.7784431137724551, 0.0, 0.7305389221556886, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 5/50 was 1.6070869498782687\n",
      "The total balanced accuracy for validation was 0.3191616766467066\n",
      "The validation loss was :   5/50 was 1.6073296145764653\n",
      "The unbalanced validation accuracy is 0.3191616766467066\n",
      "The accuracy for each is [0.9221556886227545, 0.0, 0.6736526946107785, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 6/50 was 1.6069969115433869\n",
      "The total balanced accuracy for validation was 0.3149700598802395\n",
      "The validation loss was :   6/50 was 1.6071324520482275\n",
      "The unbalanced validation accuracy is 0.3149700598802395\n",
      "The accuracy for each is [0.9520958083832335, 0.0, 0.6227544910179641, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 7/50 was 1.6067813325811315\n",
      "The total balanced accuracy for validation was 0.30479041916167665\n",
      "The validation loss was :   7/50 was 1.6069366160267127\n",
      "The unbalanced validation accuracy is 0.30479041916167665\n",
      "The accuracy for each is [0.9520958083832335, 0.0, 0.5718562874251497, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 8/50 was 1.6070269169630829\n",
      "The total balanced accuracy for validation was 0.2898203592814371\n",
      "The validation loss was :   8/50 was 1.6067416463069573\n",
      "The unbalanced validation accuracy is 0.2898203592814371\n",
      "The accuracy for each is [0.9550898203592815, 0.0, 0.4940119760479042, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 9/50 was 1.6066397516815751\n",
      "The total balanced accuracy for validation was 0.27784431137724547\n",
      "The validation loss was :   9/50 was 1.6065470280761491\n",
      "The unbalanced validation accuracy is 0.2778443113772455\n",
      "The accuracy for each is [0.9610778443113772, 0.0, 0.4281437125748503, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 10/50 was 1.6061864649807964\n",
      "The total balanced accuracy for validation was 0.2658682634730539\n",
      "The validation loss was :   10/50 was 1.6063529589219008\n",
      "The unbalanced validation accuracy is 0.26586826347305387\n",
      "The accuracy for each is [0.9610778443113772, 0.0, 0.36826347305389223, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 11/50 was 1.6058016971305564\n",
      "The total balanced accuracy for validation was 0.2622754491017964\n",
      "The validation loss was :   11/50 was 1.6061593475456009\n",
      "The unbalanced validation accuracy is 0.2622754491017964\n",
      "The accuracy for each is [0.9730538922155688, 0.0, 0.3383233532934132, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 12/50 was 1.60585527949863\n",
      "The total balanced accuracy for validation was 0.25389221556886227\n",
      "The validation loss was :   12/50 was 1.6059679922229515\n",
      "The unbalanced validation accuracy is 0.25389221556886227\n",
      "The accuracy for each is [0.9850299401197605, 0.0, 0.2844311377245509, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 13/50 was 1.6054383560463235\n",
      "The total balanced accuracy for validation was 0.24790419161676644\n",
      "The validation loss was :   13/50 was 1.6057748908768157\n",
      "The unbalanced validation accuracy is 0.24790419161676647\n",
      "The accuracy for each is [0.9910179640718563, 0.0, 0.24850299401197604, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 14/50 was 1.6052152315775554\n",
      "The total balanced accuracy for validation was 0.24550898203592814\n",
      "The validation loss was :   14/50 was 1.6055840212427928\n",
      "The unbalanced validation accuracy is 0.24550898203592814\n",
      "The accuracy for each is [0.9970059880239521, 0.0, 0.23053892215568864, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 15/50 was 1.6053821863951507\n",
      "The total balanced accuracy for validation was 0.24191616766467067\n",
      "The validation loss was :   15/50 was 1.605392231198842\n",
      "The unbalanced validation accuracy is 0.24191616766467067\n",
      "The accuracy for each is [1.0, 0.0, 0.20958083832335328, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 16/50 was 1.604842636320326\n",
      "The total balanced accuracy for validation was 0.237125748502994\n",
      "The validation loss was :   16/50 was 1.6052006541611905\n",
      "The unbalanced validation accuracy is 0.237125748502994\n",
      "The accuracy for each is [1.0, 0.0, 0.18562874251497005, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 17/50 was 1.6051437943070024\n",
      "The total balanced accuracy for validation was 0.23353293413173654\n",
      "The validation loss was :   17/50 was 1.6050104648767116\n",
      "The unbalanced validation accuracy is 0.23353293413173654\n",
      "The accuracy for each is [1.0, 0.0, 0.16766467065868262, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 18/50 was 1.6046546521010223\n",
      "The total balanced accuracy for validation was 0.22994011976047904\n",
      "The validation loss was :   18/50 was 1.6048206901121995\n",
      "The unbalanced validation accuracy is 0.22994011976047904\n",
      "The accuracy for each is [1.0, 0.0, 0.1497005988023952, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 19/50 was 1.6045369263048526\n",
      "The total balanced accuracy for validation was 0.22874251497005987\n",
      "The validation loss was :   19/50 was 1.6046311936692563\n",
      "The unbalanced validation accuracy is 0.22874251497005987\n",
      "The accuracy for each is [1.0, 0.0, 0.1437125748502994, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 20/50 was 1.604423823180022\n",
      "The total balanced accuracy for validation was 0.22634730538922154\n",
      "The validation loss was :   20/50 was 1.604441481507467\n",
      "The unbalanced validation accuracy is 0.22634730538922157\n",
      "The accuracy for each is [1.0, 0.0, 0.1317365269461078, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 21/50 was 1.6042057673136394\n",
      "The total balanced accuracy for validation was 0.22035928143712574\n",
      "The validation loss was :   21/50 was 1.6042540487415062\n",
      "The unbalanced validation accuracy is 0.22035928143712574\n",
      "The accuracy for each is [1.0, 0.0, 0.10179640718562874, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 22/50 was 1.6038699635752924\n",
      "The total balanced accuracy for validation was 0.2179640718562874\n",
      "The validation loss was :   22/50 was 1.6040663694907091\n",
      "The unbalanced validation accuracy is 0.2179640718562874\n",
      "The accuracy for each is [1.0, 0.0, 0.08982035928143713, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 23/50 was 1.6041081967177215\n",
      "The total balanced accuracy for validation was 0.21616766467065868\n",
      "The validation loss was :   23/50 was 1.6038791687188747\n",
      "The unbalanced validation accuracy is 0.21616766467065868\n",
      "The accuracy for each is [1.0, 0.0, 0.08083832335329341, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 24/50 was 1.603981234409191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total balanced accuracy for validation was 0.21437125748502991\n",
      "The validation loss was :   24/50 was 1.6036921423352408\n",
      "The unbalanced validation accuracy is 0.21437125748502994\n",
      "The accuracy for each is [1.0, 0.0, 0.0718562874251497, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 25/50 was 1.6034024909690574\n",
      "The total balanced accuracy for validation was 0.21017964071856285\n",
      "The validation loss was :   25/50 was 1.6035047504002462\n",
      "The unbalanced validation accuracy is 0.21017964071856288\n",
      "The accuracy for each is [1.0, 0.0, 0.05089820359281437, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 26/50 was 1.6036051070248638\n",
      "The total balanced accuracy for validation was 0.20598802395209578\n",
      "The validation loss was :   26/50 was 1.6033186345043298\n",
      "The unbalanced validation accuracy is 0.2059880239520958\n",
      "The accuracy for each is [1.0, 0.0, 0.029940119760479042, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 27/50 was 1.6032014025582209\n",
      "The total balanced accuracy for validation was 0.20419161676646708\n",
      "The validation loss was :   27/50 was 1.6031328242695975\n",
      "The unbalanced validation accuracy is 0.20419161676646708\n",
      "The accuracy for each is [1.0, 0.0, 0.020958083832335328, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 28/50 was 1.6031614144643147\n",
      "The total balanced accuracy for validation was 0.20239520958083834\n",
      "The validation loss was :   28/50 was 1.6029473706633746\n",
      "The unbalanced validation accuracy is 0.20239520958083831\n",
      "The accuracy for each is [1.0, 0.0, 0.011976047904191617, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 29/50 was 1.6029241261658844\n",
      "The total balanced accuracy for validation was 0.20239520958083834\n",
      "The validation loss was :   29/50 was 1.6027614814078737\n",
      "The unbalanced validation accuracy is 0.20239520958083831\n",
      "The accuracy for each is [1.0, 0.0, 0.011976047904191617, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 30/50 was 1.6029404445930764\n",
      "The total balanced accuracy for validation was 0.20119760479041915\n",
      "The validation loss was :   30/50 was 1.602577575309548\n",
      "The unbalanced validation accuracy is 0.20119760479041915\n",
      "The accuracy for each is [1.0, 0.0, 0.005988023952095809, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 31/50 was 1.603004844100387\n",
      "The total balanced accuracy for validation was 0.20119760479041915\n",
      "The validation loss was :   31/50 was 1.602393883502412\n",
      "The unbalanced validation accuracy is 0.20119760479041915\n",
      "The accuracy for each is [1.0, 0.0, 0.005988023952095809, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 32/50 was 1.6027698914210002\n",
      "The total balanced accuracy for validation was 0.20119760479041915\n",
      "The validation loss was :   32/50 was 1.6022109324346758\n",
      "The unbalanced validation accuracy is 0.20119760479041915\n",
      "The accuracy for each is [1.0, 0.0, 0.005988023952095809, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 33/50 was 1.602758977148268\n",
      "The total balanced accuracy for validation was 0.20059880239520958\n",
      "The validation loss was :   33/50 was 1.6020279974994545\n",
      "The unbalanced validation accuracy is 0.20059880239520958\n",
      "The accuracy for each is [1.0, 0.0, 0.0029940119760479044, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 34/50 was 1.6024604594265972\n",
      "The total balanced accuracy for validation was 0.20059880239520958\n",
      "The validation loss was :   34/50 was 1.601844554461405\n",
      "The unbalanced validation accuracy is 0.20059880239520958\n",
      "The accuracy for each is [1.0, 0.0, 0.0029940119760479044, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 35/50 was 1.6022118197547064\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   35/50 was 1.601662300803704\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 36/50 was 1.6017686437677454\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   36/50 was 1.6014794076988084\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 37/50 was 1.601624572718585\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   37/50 was 1.6012947063246172\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 38/50 was 1.6015341370194047\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   38/50 was 1.6011122885578406\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 39/50 was 1.6014837556415134\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   39/50 was 1.6009323197924448\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 40/50 was 1.6010783116022747\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   40/50 was 1.600751298273395\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 41/50 was 1.6012357561676591\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   41/50 was 1.6005705436546644\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 42/50 was 1.6013135380215116\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   42/50 was 1.600390201271651\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 43/50 was 1.6010580371927332\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   43/50 was 1.6002094337326325\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 44/50 was 1.600810174588804\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   44/50 was 1.6000282584550138\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 45/50 was 1.6005378475895635\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   45/50 was 1.599848020362283\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 46/50 was 1.6003851184138544\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   46/50 was 1.599667836163572\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 47/50 was 1.6001995492864538\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   47/50 was 1.5994877814532753\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 48/50 was 1.600111100408766\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   48/50 was 1.599307975083768\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 49/50 was 1.5997285268924855\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   49/50 was 1.5991283898582003\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 50/50 was 1.5997702722196225\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   50/50 was 1.5989493370056151\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train123 = trainer(\n",
    "    logRegWithHidden,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/test_4_5_data.json\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'u'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a5b7b8b83a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-a5b7b8b83a77>\u001b[0m in \u001b[0;36mtester\u001b[0;34m(model, pathToWrite)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpathToWrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'results/submission{datetime.now().strftime(\"%d_%H:%M\")}.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Get test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDataFromJSON\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/test_4_5_data.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# get our guesses from the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mguesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/School/research/DeepLearningSolarFlares/normalizer.py\u001b[0m in \u001b[0;36mgetDataFromJSON\u001b[0;34m(path, earlyStop, device, test)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# This function also ignores any lines with a value of NaN.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# This function also only gets the amount of lines we either want or need - it will stop at the earlier of earlystop and the end of file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlyStop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Check when we want to stop - the end of the file or earlier.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/School/research/DeepLearningSolarFlares/normalizer.py\u001b[0m in \u001b[0;36mcounter\u001b[0;34m(filename, lines)\u001b[0m\n\u001b[1;32m     81\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                         \u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflares\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                         \u001b[0mrow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'u'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def tester(model, pathToWrite=None):\n",
    "    if pathToWrite is None:\n",
    "        pathToWrite = f'results/submission{datetime.now().strftime(\"%d_%H:%M\")}.csv'\n",
    "    # Get test data\n",
    "    test, ids, _ = getDataFromJSON(path='data/test_4_5_data.json', test=True, device=device)\n",
    "    # get our guesses from the network\n",
    "    guesses = torch.argmax(model(test))\n",
    "    assert len(ids) == guesses.shape\n",
    "    # Open a file to write to\n",
    "    file = open(pathToWrite, mode='w')\n",
    "    print('Id,Label', file=file)\n",
    "    for i in range(len(ids)):\n",
    "        print(ids[i], guesses[i], sep=',', file=file)\n",
    "    file.close()\n",
    "\n",
    "tester(train123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "acc = \n",
    "PATH = f'savedModels/lr{lr}acc{acc}time{datetime.now().strftime(\"%d_%H:%M\")}.pth'\n",
    "torch.save(newModel.state_dict(), PATH)\n",
    "print('REMEMBER TO DELETE YOUR ACCURACY SO THE NEXT PERSON REMEMBERS TO WRITE THEIRS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
