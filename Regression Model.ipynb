{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'getTotalAccuracy' from 'normalizer' (/home/robjohnson/School/research/DeepLearningSolarFlares/normalizer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5bf5ff774b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnormalizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubSample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetDataFromJSON\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetTotalAccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m \u001b[0;31m# Change this to cuda for GPU enabled computers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'getTotalAccuracy' from 'normalizer' (/home/robjohnson/School/research/DeepLearningSolarFlares/normalizer.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from normalizer import subSample, getDataFromJSON, trainer, getTotalAccuracy\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # Change this to cuda for GPU enabled computers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file has 77270 data points. 71633 do not have NAN values.\n",
    "# %time train1, labels1, weights1 = getDataFromJSON(path=\"data/train_partition1_data.json\", earlyStop=-1)\n",
    "train1, labels1 = subSample(\"data/train_partition1_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file has 93767 data points. 82425 of them do not have NAN values.  \n",
    "# %time train2, labels2, weights2 = getDataFromJSON(path=\"data/train_partition2_data.json\", earlyStop=-1)\n",
    "train2, labels2 = subSample(\"data/train_partition2_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file has 42986 data points. 37759 of them do not have NAN values.  \n",
    "# %time train3, labels3, weights3 = getDataFromJSON(path=\"data/train_partition3_data.json\", earlyStop=-1)\n",
    "train3, labels3 = subSample(\"data/train_partition3_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network. Make sure to end with nn.Softmax activation\n",
    "import torch.nn as nn\n",
    "# from skorch import NeuralNet\n",
    "\n",
    "class logRegWithHidden(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, num_classes=5, drop1=.5, input_size=1980):\n",
    "        super().__init__() \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layerout = nn.Linear(hidden_size2, num_classes)\n",
    "        #Define a RELU Activation unit\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.smax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(p=drop1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Forward Propagate through the layers as defined above\n",
    "        y = self.drop(x.reshape(-1, 1980))\n",
    "        y = self.drop(self.relu(self.layer1(y)))\n",
    "        y = self.relu(self.layer2(y))\n",
    "        y = self.layerout(y)\n",
    "        y = self.smax(y)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust hyper parameters with 3 fold validation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelArgs = [4096*4, 2048*4]\n",
    "modelKwargs = {'drop1':.25}\n",
    "trainKwargs = {'epochs':50, 'lr':0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train1Args = [logRegWithHidden, torch.cat((train1, train2), dim=0), labels1 + labels2, None, train3, labels3, None]\n",
    "%time train12 = trainer(*train1Args, *modelArgs, **trainKwargs, **modelKwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train13 = trainer(\n",
    "    logRegWithHidden,\n",
    "    torch.cat((train1, train3), dim=0),\n",
    "    labels1 + labels3,\n",
    "    None,\n",
    "    train2,\n",
    "    labels2,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train23 = trainer(\n",
    "    logRegWithHidden,\n",
    "    torch.cat((train3, train2), dim=0),\n",
    "    labels3 + labels2,\n",
    "    None,\n",
    "    train1,\n",
    "    labels1,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = getTotalAccuracy(train12, train23, train13, \n",
    "                       torch.cat((train1, train2, train3), dim=0)\n",
    "                      labels1 + labels2 + labels3)\n",
    "print('Average accuracy of all three models on all data: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model creation for testing ##\n",
    "\n",
    "Once acceptable hyperparameters have been established, run this code to train on all the data and print out a CSV that predicts from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train123 = trainer(\n",
    "    logRegWithHidden,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def tester(model, pathToWrite=None):\n",
    "    if pathToWrite is None:\n",
    "        pathToWrite = f'results/submission{datetime.now().strftime(\"%d_%H:%M\")}.csv'\n",
    "    # Get test data\n",
    "    test, ids, _ = getDataFromJSON(path='data/test_4_5_data.json', test=True, device=device)\n",
    "    # get our guesses from the network\n",
    "    guesses = torch.argmax(model(test))\n",
    "    assert len(ids) == guesses.shape\n",
    "    # Open a file to write to\n",
    "    file = open(pathToWrite, mode='w')\n",
    "    print('Id,Label', file=file)\n",
    "    for i in range(len(ids)):\n",
    "        print(ids[i], guesses[i], sep=',', file=file)\n",
    "    file.close()\n",
    "\n",
    "tester(train123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "acc = \n",
    "PATH = f'savedModels/lr{lr}acc{acc}time{datetime.now().strftime(\"%d_%H:%M\")}.pth'\n",
    "torch.save(newModel.state_dict(), PATH)\n",
    "print('REMEMBER TO DELETE YOUR ACCURACY SO THE NEXT PERSON REMEMBERS TO WRITE THEIRS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
