{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from normalizer import counter\n",
    "from torch.utils.data import DataLoader\n",
    "from normalizer import getDataFromJSON, subSample, trainer, tester, getTotalAccuracy, cfvalidation\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNet\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file has 77270 data points. \n",
    "%time train1, labels1 = subSample(path=\"data/train_partition1_data.json\", earlyStop=10000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file has 93767 data points. \n",
    "%time train2, labels2 = subSample(path=\"data/train_partition2_data.json\", earlyStop=10000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file has 42986 data points. \n",
    "%time train3, labels3 = subSample(path=\"data/train_partition3_data.json\", earlyStop=10000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network ##\n",
    "\n",
    "This network has two parts - the stack and the fully connected layers. The stack interprets a given measurement and then outputs from 60 to a given number of entries. The fully connected part then makes a prediction off of all of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a network that takes each individual time series as input and outputs an nx33 tensor\n",
    "\n",
    "class stack(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__() \n",
    "        self.n = n\n",
    "        self.layer00 = nn.Linear(60,n)\n",
    "        self.layer01 = nn.Linear(60,n)\n",
    "        self.layer02 = nn.Linear(60,n)\n",
    "        self.layer03 = nn.Linear(60,n)\n",
    "        self.layer04 = nn.Linear(60,n)\n",
    "        self.layer05 = nn.Linear(60,n)\n",
    "        self.layer06 = nn.Linear(60,n)\n",
    "        self.layer07 = nn.Linear(60,n)\n",
    "        self.layer08 = nn.Linear(60,n)\n",
    "        self.layer09 = nn.Linear(60,n)\n",
    "        self.layer10 = nn.Linear(60,n)\n",
    "        self.layer11 = nn.Linear(60,n)\n",
    "        self.layer12 = nn.Linear(60,n)\n",
    "        self.layer13 = nn.Linear(60,n)\n",
    "        self.layer14 = nn.Linear(60,n)\n",
    "        self.layer15 = nn.Linear(60,n)\n",
    "        self.layer16 = nn.Linear(60,n)\n",
    "        self.layer17 = nn.Linear(60,n)\n",
    "        self.layer18 = nn.Linear(60,n)\n",
    "        self.layer19 = nn.Linear(60,n)\n",
    "        self.layer20 = nn.Linear(60,n)\n",
    "        self.layer21 = nn.Linear(60,n)\n",
    "        self.layer22 = nn.Linear(60,n)\n",
    "        self.layer23 = nn.Linear(60,n)\n",
    "        self.layer24 = nn.Linear(60,n)\n",
    "        self.layer25 = nn.Linear(60,n)\n",
    "        self.layer26 = nn.Linear(60,n)\n",
    "        self.layer27 = nn.Linear(60,n)\n",
    "        self.layer28 = nn.Linear(60,n)\n",
    "        self.layer29 = nn.Linear(60,n)\n",
    "        self.layer30 = nn.Linear(60,n)\n",
    "        self.layer31 = nn.Linear(60,n)\n",
    "        self.layer32 = nn.Linear(60,n)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.zeros(x.shape[0], 33, self.n)\n",
    "        output[:,0,:] = self.layer00(x[:,0,:])\n",
    "        output[:,1,:] = self.layer01(x[:,1,:])\n",
    "        output[:,2,:] = self.layer02(x[:,2,:])\n",
    "        output[:,3,:] = self.layer03(x[:,3,:])\n",
    "        output[:,4,:] = self.layer04(x[:,4,:])\n",
    "        output[:,5,:] = self.layer05(x[:,5,:])\n",
    "        output[:,6,:] = self.layer06(x[:,6,:])\n",
    "        output[:,7,:] = self.layer07(x[:,7,:])\n",
    "        output[:,8,:] = self.layer08(x[:,8,:])\n",
    "        output[:,9,:] = self.layer09(x[:,9,:])\n",
    "        \n",
    "        output[:,10,:] = self.layer00(x[:,10,:])\n",
    "        output[:,11,:] = self.layer00(x[:,11,:])\n",
    "        output[:,12,:] = self.layer00(x[:,12,:])\n",
    "        output[:,13,:] = self.layer00(x[:,13,:])\n",
    "        output[:,14,:] = self.layer00(x[:,14,:])\n",
    "        output[:,15,:] = self.layer00(x[:,15,:])\n",
    "        output[:,16,:] = self.layer00(x[:,16,:])\n",
    "        output[:,17,:] = self.layer00(x[:,17,:])\n",
    "        output[:,18,:] = self.layer00(x[:,18,:])\n",
    "        output[:,19,:] = self.layer00(x[:,19,:])\n",
    "        \n",
    "        output[:,20,:] = self.layer00(x[:,20,:])\n",
    "        output[:,21,:] = self.layer00(x[:,21,:])\n",
    "        output[:,22,:] = self.layer00(x[:,22,:])\n",
    "        output[:,23,:] = self.layer00(x[:,23,:])\n",
    "        output[:,24,:] = self.layer00(x[:,24,:])\n",
    "        output[:,25,:] = self.layer00(x[:,25,:])\n",
    "        output[:,26,:] = self.layer00(x[:,26,:])\n",
    "        output[:,27,:] = self.layer00(x[:,27,:])\n",
    "        output[:,28,:] = self.layer00(x[:,28,:])\n",
    "        output[:,29,:] = self.layer00(x[:,29,:])\n",
    "        \n",
    "        output[:,30,:] = self.layer00(x[:,30,:])\n",
    "        output[:,31,:] = self.layer00(x[:,31,:])\n",
    "        output[:,32,:] = self.layer00(x[:,32,:])\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network. Make sure to end with nn.Softmax activation    \n",
    "    \n",
    "class CNNinspired(nn.Module):\n",
    "    def __init__(self, n, hidden_size, num_classes=5, drop1=.5):\n",
    "        super().__init__() \n",
    "        self.n = n\n",
    "        self.layer1 = stack(n)\n",
    "        self.layer2 = nn.Linear(n*33, hidden_size)\n",
    "        self.layerout = nn.Linear(hidden_size, num_classes)\n",
    "        #Define a RELU Activation unit\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.smax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(p=drop1)\n",
    "        self.b = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Forward Propagate through the layers as defined above\n",
    "        output = self.layer1(x)\n",
    "        if self.b:\n",
    "            self.out = output\n",
    "            self.b = False\n",
    "#         print(x.shape)\n",
    "#         print('This is iffy')\n",
    "#         print(output.shape)\n",
    "#         assert False\n",
    "        y = self.sig( output.reshape(-1, 33*self.n))\n",
    "        y = self.relu(self.layer2(y))\n",
    "        y = self.smax(self.layerout(y))\n",
    "        return y \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin testing with three fold validation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelArgs = [3, 128]\n",
    "modelKwargs = {'drop1':.25}\n",
    "trainKwargs = {'epochs':50, 'lr' : 0.01}\n",
    "# Attempted learing rates: \n",
    "# 0.00001 - one in a million change\n",
    "# 0.000001 - one in 10 million\n",
    "# 0.0001 - one in 100 thousand\n",
    "# 0.001 with 128 hidden neurons instead of 30 - one in 10 thousand\n",
    "\n",
    "    # model1 = CNNinspired(1, 30)\n",
    "    # model3 = CNNinspired(3, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train1Args = [CNNinspired, torch.cat((train1, train2), dim=0), labels1 + labels2, None, train3, labels3, None]\n",
    "%time train12 = trainer(*train1Args, *modelArgs, **trainKwargs, **modelKwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train13 = trainer(\n",
    "    CNNinspired,\n",
    "    torch.cat((train1, train3), dim=0),\n",
    "    labels1 + labels3,\n",
    "    None,\n",
    "    train2,\n",
    "    labels2,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train23 = trainer(\n",
    "    CNNinspired,\n",
    "    torch.cat((train3, train2), dim=0),\n",
    "    labels3 + labels2,\n",
    "    None,\n",
    "    train1,\n",
    "    labels1,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = getTotalAccuracy(train12, train23, train13, \n",
    "                       torch.cat((train1, train2, train3), dim=0),\n",
    "                       labels1 + labels2 + labels3)\n",
    "print('Average accuracy of all three models on all data: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cfvalidation(tripList, module, x1, y1, x2, y2, x3, y3, **trainKwargs):\n",
    "#         for (modelArgs, modelKwargs, lr) in tripList:\n",
    "ns = [1,3,5,7]\n",
    "hls = [30, 128, 256]\n",
    "margs = []\n",
    "for n in ns:\n",
    "    for h in hls:\n",
    "        margs.append([n,h])\n",
    "lrs = [10**i for i in range(0,-5, -1)]\n",
    "drs = [0, .05, .25, .45, .5]\n",
    "tripList = []\n",
    "for ma in margs:\n",
    "    for r in lrs:\n",
    "        for d in drs:\n",
    "            tripList.append([ma, {'drop1': d}, r])\n",
    "lossArgs, quickArgs = cfvalidation(tripList, CNNinspired, train1, labels1, train2, labels2, train3, labels3, 200)\n",
    "print(lossArgs, quickArgs, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model creation for testing ##\n",
    "\n",
    "Once acceptable hyperparameters have been established, run this code to train on all the data and print out a CSV that predicts from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bd1f1ea5ef8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train123 = trainer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mCNNinspired\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabels2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabels3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "train123 = trainer(\n",
    "    CNNinspired,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    epochs=1,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# def tester(model, pathToWrite=None):\n",
    "#     if pathToWrite is None:\n",
    "#         pathToWrite = f'results/submission{datetime.now().strftime(\"%d_%H:%M\")}.csv'\n",
    "#     # Get test data\n",
    "#     test, ids, _ = getDataFromJSON(path='data/test_4_5_data.json', test=True, device=device)\n",
    "#     # get our guesses from the network\n",
    "#     guesses = torch.argmax(model(test))\n",
    "#     assert len(ids) == guesses.shape\n",
    "#     # Open a file to write to\n",
    "#     file = open(pathToWrite, mode='w')\n",
    "#     print('Id,Label', file=file)\n",
    "#     for i in range(len(ids)):\n",
    "#         print(ids[i], guesses[i], sep=',', file=file)\n",
    "#     file.close()\n",
    "\n",
    "tester(train123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "acc = \n",
    "PATH = f'savedModels/lr{lr}acc{acc}time{datetime.now().strftime(\"%d_%H:%M\")}.pth'\n",
    "torch.save(newModel.state_dict(), PATH)\n",
    "print('REMEMBER TO DELETE YOUR ACCURACY SO THE NEXT PERSON REMEMBERS TO WRITE THEIRS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
