{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't have the data, download it\n",
    "!wget https://dmlab.cs.gsu.edu/solar/data/data-comp-2020/train_partition1_data.json\n",
    "!mkdir data\n",
    "!mv train_partition1_data.json data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robjohnson/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from normalizer import counter, subSample\n",
    "from torch.utils.data import DataLoader\n",
    "from normalizer import subSample, getDataFromJSON, trainer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # Change this to cuda for GPU enabled computers\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition1_data.json\n",
      "Now loading event 1/785\n",
      "Now loading event 101/785\n",
      "Now loading event 201/785\n",
      "Now loading event 301/785\n",
      "Now loading event 401/785\n",
      "Now loading event 501/785\n",
      "Now loading event 601/785\n",
      "Now loading event 701/785\n",
      "785 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "train1, labels1 = subSample(\"data/train_partition1_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network. Make sure to end with nn.Softmax activation\n",
    "import torch.nn as nn\n",
    "# from skorch import NeuralNet\n",
    "\n",
    "class logRegWithHidden(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, num_classes=5, drop1=.5, input_size=1980):\n",
    "        super().__init__() \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layerout = nn.Linear(hidden_size2, num_classes)\n",
    "        #Define a RELU Activation unit\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.smax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(p=drop1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Forward Propagate through the layers as defined above\n",
    "        y = self.drop(x.reshape(-1, 1980))\n",
    "        y = self.drop(self.relu(self.layer1(y)))\n",
    "        y = self.relu(self.layer2(y))\n",
    "        y = self.layerout(y)\n",
    "        y = self.smax(y)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(modelModule, inputs, labels, weight, valSets, valLabels, valweight, *modelArgs, lr=0.0001, epochs=50,\n",
    "#           pmodel = False, pstateDict = False, pindvLoss = False, pmodelDict = False, pvalidateOut = False,\n",
    "#           pbl = False, checkClone = False, pbalApp = False, **modelKwargs):\n",
    "    \n",
    "#     '''\n",
    "#     function call: \n",
    "#     train(modelModule, inputs, labels, weight, valSets, valLabels, valweight, *modelArgs, lr=0.0001, \n",
    "#           pmodel = False, pstateDict = False, pindvLoss = False, pmodelDict = False, pvalidateOut = False,\n",
    "#           pbl = False, checkClone = False **modelKwargs):\n",
    "    \n",
    "#     modelModule is the nn.module form of the network you want trained\n",
    "#     inputs and labels are the Xs and Ys respectively of the training data\n",
    "#     weights are the weights to use for the cross entropy loss function - see more in counter documentation\n",
    "#     valinputs, valLabels, and valweight are the same fields but for our validation set\n",
    "#     lr is the learning rate for the optimizer\n",
    "#     Epochs is the amount of times a network is trained on the data\n",
    "#     pmodel prints the model if True, defaults to False\n",
    "#     pstateDict prints the state dict for the optimizer if True, defaults to False\n",
    "#     pindvLoss prints the individual loss for each minibatch if True, defaults to False\n",
    "#     pmodelDict prints the state dictionary for the model if True, defaults to False\n",
    "#     pvalidateOut prints all errors and accuracies of the validation set if True, defaults to False\n",
    "#     pbl prints the batch loss at declaration time if True, defaults to False\n",
    "#     checkClone prints the maximum and the minimum difference between the initial model and the current iteration \n",
    "#         of the model if True, defaults to False\n",
    "#     pblApp checks the validation appending\n",
    "#     modelArgs and modelKwargs are the arguments for the model and the keyword arguments of the model, repsectivley\n",
    "#     '''\n",
    "\n",
    "#     # Define the model\n",
    "#     model = modelModule(*modelArgs, **modelKwargs)\n",
    "#     # if we are going to check this against itself to make sure it is learning, we need to be able to come back\n",
    "#     if checkClone: \n",
    "#         PATH = './.cloneModel.pth'\n",
    "#         torch.save(model.state_dict(), PATH)\n",
    "#     if pmodel: print(model)\n",
    "    \n",
    "#     # Define loss functions\n",
    "#     if weight is not None: weight = torch.Tensor(weight)\n",
    "#     lfc = nn.CrossEntropyLoss(weight=weight)\n",
    "#     if valweight is not None: valweight = torch.Tensor(valweight)\n",
    "#     valLoss = nn.CrossEntropyLoss(weight=valweight)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "#     # Hyperparameters\n",
    "#     batch = 64\n",
    "    \n",
    "#     # Start a dataloader object\n",
    "#     data = list(zip(inputs,labels))\n",
    "#     val = list(zip(valSets,valLabels))\n",
    "#     loader = DataLoader(data, batch_size = batch, num_workers=4)\n",
    "#     valLoader = DataLoader(val, batch_size = 1, num_workers=4)\n",
    "#     opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.25)\n",
    "#     if pstateDict: print(opt.state_dict())\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         batch_loss = []\n",
    "#         if pbl: print(batch_loss)\n",
    "#         for (xtrain,ytrain) in loader:\n",
    "#             opt.zero_grad()\n",
    "#             if pstateDict: print('Opt dict post zero grad:', '================',opt.state_dict(), sep='\\n')\n",
    "#             output = model(xtrain)\n",
    "#             loss = lfc(output,ytrain)\n",
    "#             if pindvLoss: print(loss)\n",
    "#             loss.backward()\n",
    "#             if pstateDict: print('Opt dict post backward:', '================',opt.state_dict(), sep='\\n')\n",
    "#             if pmodelDict: print(model.state_dict())\n",
    "#             opt.step()\n",
    "#             if pstateDict: print('Opt dict post step:', '================',opt.state_dict(), sep='\\n')\n",
    "#             if pstateDict or pmodelDict: print('\\n\\n\\n\\n\\n')\n",
    "#             batch_loss.append(loss.item())\n",
    "#         print(f'The training loss for epoch {epoch+1}/{epochs} was {np.mean(batch_loss)}')\n",
    "#         if pbl: print(batch_loss)\n",
    "        \n",
    "#         model.eval()\n",
    "#         balanced = [[],[],[],[],[]]\n",
    "#         batchLoss = []\n",
    "#         unbalanced = []\n",
    "        \n",
    "#         for (xval,yval) in valLoader:\n",
    "#             output = model(xval)\n",
    "#             loss = valLoss(output,yval)\n",
    "#             batchLoss.append(loss.item())\n",
    "#             guesses = torch.argmax(output,1)\n",
    "#             if pvalidateOut : print('output: \\n',output)\n",
    "#             corrects = yval.clone().detach() == guesses\n",
    "#             if pvalidateOut: print(yval.clone().detach(), guesses)\n",
    "#             if pvalidateOut: print(corrects.detach())\n",
    "#             if pvalidateOut: print('===========================\\n\\n\\n')\n",
    "#             unbalanced.append([1 if correct else 0 for correct in corrects.detach()])\n",
    "        \n",
    "#             for i, ans in enumerate(yval):\n",
    "#                 if pbalApp: print(i,ans, guesses[i], corrects[i])\n",
    "#                 balanced[ans].append(corrects[i])\n",
    "        \n",
    "#         balanced = [np.mean(i) for i in balanced]\n",
    "#         balancedAccuracy = np.mean(balanced)\n",
    "        \n",
    "#         print(f'The total balanced accuracy for validation was {balancedAccuracy}')\n",
    "#         print(f'The validation loss was :   {epoch+1}/{epochs} was {np.mean(batchLoss)}')\n",
    "#         print(f'The unbalanced validation accuracy is {np.mean(unbalanced)}')\n",
    "#         print(f'The accuracy for each is {balanced}')       \n",
    "        \n",
    "        \n",
    "#         if checkClone:\n",
    "#             fives = modelModule(*modelArgs, **modelKwargs)\n",
    "#             fives.load_state_dict(torch.load(PATH))\n",
    "#             s=2\n",
    "#             feature_extraction1 = [child for child in model.children()]\n",
    "#             print(feature_extraction1[s])\n",
    "#             feature_extraction2 = [child for child in fives.children()]\n",
    "#             print(feature_extraction2[s])\n",
    "#             print(torch.max(feature_extraction1[s].weight - feature_extraction2[s].weight).detach())\n",
    "#             print(torch.min(feature_extraction1[s].weight - feature_extraction2[s].weight).detach())\n",
    "#         print('\\n\\n=============End Epoch==============\\n\\n')\n",
    "#     if pstateDict: print(opt.state_dict())\n",
    "\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/40 was 1.6036966030414288\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   1/40 was 1.5972699827449337\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 2/40 was 1.592959110553448\n",
      "The total balanced accuracy for validation was 0.2535031847133758\n",
      "The validation loss was :   2/40 was 1.5876273387556623\n",
      "The unbalanced validation accuracy is 0.2535031847133758\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.267515923566879]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 3/40 was 1.5836453162706816\n",
      "The total balanced accuracy for validation was 0.30573248407643316\n",
      "The validation loss was :   3/40 was 1.578737127249408\n",
      "The unbalanced validation accuracy is 0.3057324840764331\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.5286624203821656]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 4/40 was 1.57470008960137\n",
      "The total balanced accuracy for validation was 0.332484076433121\n",
      "The validation loss was :   4/40 was 1.5696733793635278\n",
      "The unbalanced validation accuracy is 0.332484076433121\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.6624203821656051]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 5/40 was 1.5652288106771617\n",
      "The total balanced accuracy for validation was 0.3401273885350318\n",
      "The validation loss was :   5/40 was 1.5597426309707059\n",
      "The unbalanced validation accuracy is 0.3401273885350318\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.7006369426751592]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 6/40 was 1.554756448819087\n",
      "The total balanced accuracy for validation was 0.35031847133757965\n",
      "The validation loss was :   6/40 was 1.5487512728211226\n",
      "The unbalanced validation accuracy is 0.3503184713375796\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.7515923566878981]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 7/40 was 1.5432444444069495\n",
      "The total balanced accuracy for validation was 0.35541401273885354\n",
      "The validation loss was :   7/40 was 1.5368722112315476\n",
      "The unbalanced validation accuracy is 0.3554140127388535\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.7770700636942676]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 8/40 was 1.5311010067279522\n",
      "The total balanced accuracy for validation was 0.3605095541401274\n",
      "The validation loss was :   8/40 was 1.5247896335686848\n",
      "The unbalanced validation accuracy is 0.36050955414012736\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.802547770700637]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 9/40 was 1.5190869844876802\n",
      "The total balanced accuracy for validation was 0.3745222929936306\n",
      "The validation loss was :   9/40 was 1.513293986715329\n",
      "The unbalanced validation accuracy is 0.37452229299363055\n",
      "The accuracy for each is [1.0, 0.050955414012738856, 0.0, 0.0, 0.821656050955414]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 10/40 was 1.5079128742218018\n",
      "The total balanced accuracy for validation was 0.39872611464968155\n",
      "The validation loss was :   10/40 was 1.5029519629326595\n",
      "The unbalanced validation accuracy is 0.39872611464968155\n",
      "The accuracy for each is [1.0, 0.1592356687898089, 0.0, 0.0, 0.8343949044585988]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 11/40 was 1.4979871419759898\n",
      "The total balanced accuracy for validation was 0.41401273885350315\n",
      "The validation loss was :   11/40 was 1.4939481707894877\n",
      "The unbalanced validation accuracy is 0.4140127388535032\n",
      "The accuracy for each is [1.0, 0.22929936305732485, 0.0, 0.0, 0.8407643312101911]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 12/40 was 1.489377104319059\n",
      "The total balanced accuracy for validation was 0.4343949044585987\n",
      "The validation loss was :   12/40 was 1.4861900976509046\n",
      "The unbalanced validation accuracy is 0.43439490445859874\n",
      "The accuracy for each is [1.0, 0.33121019108280253, 0.0, 0.0, 0.8407643312101911]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 13/40 was 1.4819330068734975\n",
      "The total balanced accuracy for validation was 0.44203821656050957\n",
      "The validation loss was :   13/40 was 1.4794694437342844\n",
      "The unbalanced validation accuracy is 0.44203821656050957\n",
      "The accuracy for each is [1.0, 0.37579617834394907, 0.0, 0.0, 0.8343949044585988]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 14/40 was 1.4754403279377863\n",
      "The total balanced accuracy for validation was 0.45095541401273886\n",
      "The validation loss was :   14/40 was 1.473553712580614\n",
      "The unbalanced validation accuracy is 0.45095541401273886\n",
      "The accuracy for each is [1.0, 0.4267515923566879, 0.0, 0.0, 0.8280254777070064]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 15/40 was 1.4696777508809016\n",
      "The total balanced accuracy for validation was 0.4573248407643312\n",
      "The validation loss was :   15/40 was 1.468242260301189\n",
      "The unbalanced validation accuracy is 0.4573248407643312\n",
      "The accuracy for each is [1.0, 0.4585987261146497, 0.0, 0.0, 0.8280254777070064]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 16/40 was 1.4644719912455633\n",
      "The total balanced accuracy for validation was 0.4598726114649681\n",
      "The validation loss was :   16/40 was 1.4633876360146103\n",
      "The unbalanced validation accuracy is 0.45987261146496816\n",
      "The accuracy for each is [1.0, 0.4713375796178344, 0.0, 0.0, 0.8280254777070064]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 17/40 was 1.4596843811181874\n",
      "The total balanced accuracy for validation was 0.46114649681528663\n",
      "The validation loss was :   17/40 was 1.4588657956973763\n",
      "The unbalanced validation accuracy is 0.46114649681528663\n",
      "The accuracy for each is [1.0, 0.47770700636942676, 0.0, 0.0, 0.8280254777070064]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 18/40 was 1.455205147082989\n",
      "The total balanced accuracy for validation was 0.46114649681528663\n",
      "The validation loss was :   18/40 was 1.4545877983615656\n",
      "The unbalanced validation accuracy is 0.46114649681528663\n",
      "The accuracy for each is [1.0, 0.47770700636942676, 0.0, 0.0, 0.8280254777070064]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 19/40 was 1.4509610121066754\n",
      "The total balanced accuracy for validation was 0.4624203821656051\n",
      "The validation loss was :   19/40 was 1.4504984684051223\n",
      "The unbalanced validation accuracy is 0.4624203821656051\n",
      "The accuracy for each is [1.0, 0.4840764331210191, 0.0, 0.0, 0.8280254777070064]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 20/40 was 1.4468994232324452\n",
      "The total balanced accuracy for validation was 0.4624203821656051\n",
      "The validation loss was :   20/40 was 1.4465462930642876\n",
      "The unbalanced validation accuracy is 0.4624203821656051\n",
      "The accuracy for each is [1.0, 0.4840764331210191, 0.0, 0.006369426751592357, 0.821656050955414]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 21/40 was 1.4429840124570406\n",
      "The total balanced accuracy for validation was 0.4662420382165605\n",
      "The validation loss was :   21/40 was 1.4427112171604375\n",
      "The unbalanced validation accuracy is 0.4662420382165605\n",
      "The accuracy for each is [1.0, 0.4840764331210191, 0.0, 0.03821656050955414, 0.8089171974522293]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 22/40 was 1.4391914972892175\n",
      "The total balanced accuracy for validation was 0.4726114649681529\n",
      "The validation loss was :   22/40 was 1.4389780455334171\n",
      "The unbalanced validation accuracy is 0.4726114649681529\n",
      "The accuracy for each is [0.9936305732484076, 0.47770700636942676, 0.0, 0.09554140127388536, 0.7961783439490446]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 23/40 was 1.4355082328502948\n",
      "The total balanced accuracy for validation was 0.48152866242038217\n",
      "The validation loss was :   23/40 was 1.4353357967297742\n",
      "The unbalanced validation accuracy is 0.48152866242038217\n",
      "The accuracy for each is [0.9872611464968153, 0.47770700636942676, 0.0, 0.15286624203821655, 0.7898089171974523]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 24/40 was 1.431924398128803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total balanced accuracy for validation was 0.49044585987261147\n",
      "The validation loss was :   24/40 was 1.4317874367070047\n",
      "The unbalanced validation accuracy is 0.49044585987261147\n",
      "The accuracy for each is [0.9872611464968153, 0.49044585987261147, 0.0, 0.19745222929936307, 0.7770700636942676]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 25/40 was 1.4284414052963257\n",
      "The total balanced accuracy for validation was 0.5006369426751592\n",
      "The validation loss was :   25/40 was 1.4283350535259125\n",
      "The unbalanced validation accuracy is 0.5006369426751592\n",
      "The accuracy for each is [0.9872611464968153, 0.49044585987261147, 0.0, 0.25477707006369427, 0.7707006369426752]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 26/40 was 1.4250577321419349\n",
      "The total balanced accuracy for validation was 0.513375796178344\n",
      "The validation loss was :   26/40 was 1.4249830783552424\n",
      "The unbalanced validation accuracy is 0.513375796178344\n",
      "The accuracy for each is [0.9808917197452229, 0.49044585987261147, 0.0, 0.33121019108280253, 0.7643312101910829]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 27/40 was 1.4217775051410382\n",
      "The total balanced accuracy for validation was 0.5095541401273886\n",
      "The validation loss was :   27/40 was 1.421739299130288\n",
      "The unbalanced validation accuracy is 0.5095541401273885\n",
      "The accuracy for each is [0.9808917197452229, 0.4713375796178344, 0.0, 0.34394904458598724, 0.7515923566878981]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 28/40 was 1.4186055110051081\n",
      "The total balanced accuracy for validation was 0.5146496815286625\n",
      "The validation loss was :   28/40 was 1.4186119332435025\n",
      "The unbalanced validation accuracy is 0.5146496815286624\n",
      "The accuracy for each is [0.9808917197452229, 0.4713375796178344, 0.0, 0.37579617834394907, 0.7452229299363057]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 29/40 was 1.4155483337549062\n",
      "The total balanced accuracy for validation was 0.513375796178344\n",
      "The validation loss was :   29/40 was 1.4156099298957048\n",
      "The unbalanced validation accuracy is 0.513375796178344\n",
      "The accuracy for each is [0.9745222929936306, 0.45222929936305734, 0.0, 0.4012738853503185, 0.7388535031847133]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 30/40 was 1.4126105125133808\n",
      "The total balanced accuracy for validation was 0.5159235668789809\n",
      "The validation loss was :   30/40 was 1.4127303414284045\n",
      "The unbalanced validation accuracy is 0.5159235668789809\n",
      "The accuracy for each is [0.9745222929936306, 0.45222929936305734, 0.0, 0.42038216560509556, 0.732484076433121]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 31/40 was 1.4097860501362727\n",
      "The total balanced accuracy for validation was 0.5146496815286624\n",
      "The validation loss was :   31/40 was 1.4099698315000837\n",
      "The unbalanced validation accuracy is 0.5146496815286624\n",
      "The accuracy for each is [0.9745222929936306, 0.445859872611465, 0.0, 0.43312101910828027, 0.7197452229299363]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 32/40 was 1.4070741396683912\n",
      "The total balanced accuracy for validation was 0.5184713375796178\n",
      "The validation loss was :   32/40 was 1.4073290994212886\n",
      "The unbalanced validation accuracy is 0.5184713375796178\n",
      "The accuracy for each is [0.9745222929936306, 0.445859872611465, 0.0, 0.45222929936305734, 0.7197452229299363]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 33/40 was 1.404473139689519\n",
      "The total balanced accuracy for validation was 0.5171974522292994\n",
      "The validation loss was :   33/40 was 1.4048071521103003\n",
      "The unbalanced validation accuracy is 0.5171974522292994\n",
      "The accuracy for each is [0.9745222929936306, 0.445859872611465, 0.0, 0.45222929936305734, 0.7133757961783439]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 34/40 was 1.4019816747078528\n",
      "The total balanced accuracy for validation was 0.5159235668789809\n",
      "The validation loss was :   34/40 was 1.4023982250007094\n",
      "The unbalanced validation accuracy is 0.5159235668789809\n",
      "The accuracy for each is [0.9681528662420382, 0.445859872611465, 0.0, 0.4585987261146497, 0.7070063694267515]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 35/40 was 1.399594444494981\n",
      "The total balanced accuracy for validation was 0.5171974522292994\n",
      "The validation loss was :   35/40 was 1.4000951983366803\n",
      "The unbalanced validation accuracy is 0.5171974522292994\n",
      "The accuracy for each is [0.9681528662420382, 0.445859872611465, 0.0, 0.4713375796178344, 0.7006369426751592]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 36/40 was 1.397305158468393\n",
      "The total balanced accuracy for validation was 0.5184713375796178\n",
      "The validation loss was :   36/40 was 1.3978924395172458\n",
      "The unbalanced validation accuracy is 0.5184713375796178\n",
      "The accuracy for each is [0.9681528662420382, 0.45222929936305734, 0.0, 0.47770700636942676, 0.6942675159235668]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 37/40 was 1.3951080762423003\n",
      "The total balanced accuracy for validation was 0.5222929936305732\n",
      "The validation loss was :   37/40 was 1.3957850466108626\n",
      "The unbalanced validation accuracy is 0.5222929936305732\n",
      "The accuracy for each is [0.9681528662420382, 0.45222929936305734, 0.006369426751592357, 0.49044585987261147, 0.6942675159235668]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 38/40 was 1.3929989154522235\n",
      "The total balanced accuracy for validation was 0.5248407643312102\n",
      "The validation loss was :   38/40 was 1.3937659303853467\n",
      "The unbalanced validation accuracy is 0.5248407643312102\n",
      "The accuracy for each is [0.9681528662420382, 0.45222929936305734, 0.012738853503184714, 0.4968152866242038, 0.6942675159235668]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 39/40 was 1.3909721833008986\n",
      "The total balanced accuracy for validation was 0.5273885350318471\n",
      "The validation loss was :   39/40 was 1.3918295457864263\n",
      "The unbalanced validation accuracy is 0.5273885350318471\n",
      "The accuracy for each is [0.9681528662420382, 0.45222929936305734, 0.01910828025477707, 0.5031847133757962, 0.6942675159235668]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 40/40 was 1.3890247986866877\n",
      "The total balanced accuracy for validation was 0.5248407643312103\n",
      "The validation loss was :   40/40 was 1.389971122620212\n",
      "The unbalanced validation accuracy is 0.5248407643312102\n",
      "The accuracy for each is [0.9617834394904459, 0.45222929936305734, 0.01910828025477707, 0.4968152866242038, 0.6942675159235668]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "CPU times: user 53min 20s, sys: 3min 32s, total: 56min 53s\n",
      "Wall time: 14min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [weights1[i] + weights2[i] for i in range(5)]\n",
    "trainArgs = [logRegWithHidden, train1, labels1, None, train1, labels1, None]\n",
    "modelArgs = [4096*4, 2048*4]\n",
    "lr = 0.01\n",
    "# pvalidateOut=True, pbalApp=True, \n",
    "%time newModel = trainer(*trainArgs, *modelArgs, lr = lr, drop1=0)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMEMBER TO DELETE YOUR ACCURACY SO THE NEXT PERSON REMEMBERS TO WRITE THEIRS\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "acc = \n",
    "PATH = f'savedModels/lr{lr}acc{acc}time{datetime.now().strftime(\"%d_%H:%M\")}.pth'\n",
    "torch.save(newModel.state_dict(), PATH)\n",
    "print('REMEMBER TO DELETE YOUR ACCURACY SO THE NEXT PERSON REMEMBERS TO WRITE THEIRS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
