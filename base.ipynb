{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of our fields have names, but we need them in numbers, so define a dictionary to convert.\n",
    "global magDict\n",
    "magDict = {\n",
    "    'TOTUSJH': 0\n",
    "    'TOTBSQ': 1\n",
    "    'TOTPOT': 2\n",
    "    'TOTUSJZ': 3\n",
    "    'ABSNJZH': 4\n",
    "    'SAVNCPP': 5\n",
    "    'USFLUX': 6\n",
    "    'TOTFZ': 7\n",
    "    'MEANPOT': 8\n",
    "    'EPSZ': 9\n",
    "    'SHRGT45': 10\n",
    "    'MEANSHR': 11\n",
    "    'MEANGAM': 12\n",
    "    'MEANGBT': 13\n",
    "    'MEANGBZ': 14\n",
    "    'MEANGBH': 15\n",
    "    'MEANJZH': 16\n",
    "    'TOTFY': 17\n",
    "    'MEANJZD': 18\n",
    "    'MEANALP': 19\n",
    "    'TOTFX': 20\n",
    "    'EPSY': 21\n",
    "    'EPSX': 22\n",
    "    'R_VALUE': 23\n",
    "    'RBZ_VALUE': 24\n",
    "    'RBT_VALUE': 25\n",
    "    'RBP_VALUE': 26\n",
    "    'FDIM': 27\n",
    "    'BZ_FDIM': 28\n",
    "    'BT_FDIM': 29\n",
    "    'BP_FDIM': 30\n",
    "    'PIL_LEN': 31\n",
    "    'XR_MAX': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TOTUSJH': 0\n",
      "'TOTBSQ': 1\n",
      "'TOTPOT': 2\n",
      "'TOTUSJZ': 3\n",
      "'ABSNJZH': 4\n",
      "'SAVNCPP': 5\n",
      "'USFLUX': 6\n",
      "'TOTFZ': 7\n",
      "'MEANPOT': 8\n",
      "'EPSZ': 9\n",
      "'SHRGT45': 10\n",
      "'MEANSHR': 11\n",
      "'MEANGAM': 12\n",
      "'MEANGBT': 13\n",
      "'MEANGBZ': 14\n",
      "'MEANGBH': 15\n",
      "'MEANJZH': 16\n",
      "'TOTFY': 17\n",
      "'MEANJZD': 18\n",
      "'MEANALP': 19\n",
      "'TOTFX': 20\n",
      "'EPSY': 21\n",
      "'EPSX': 22\n",
      "'R_VALUE': 23\n",
      "'RBZ_VALUE': 24\n",
      "'RBT_VALUE': 25\n",
      "'RBP_VALUE': 26\n",
      "'FDIM': 27\n",
      "'BZ_FDIM': 28\n",
      "'BT_FDIM': 29\n",
      "'BP_FDIM': 30\n",
      "'PIL_LEN': 31\n",
      "'XR_MAX': 32\n",
      "0.09963967929642137\n"
     ]
    }
   ],
   "source": [
    "# Get the data from the JSON file, then return it as a tensor\n",
    "def getTrainData(num, device, path=\"../data/\"):\n",
    "    # I might need to refactor these arguments to allow to get the test data. Problem for another day.\n",
    "    # As it stands now, num is the number of the dataset, device is where to store it (CUDA), and path is the\n",
    "    # path to the directory that holds the JSON files. \n",
    "    \n",
    "    # Get the dictionary to assign names to numbers\n",
    "    global magDict\n",
    "    \n",
    "    # Get the path to the file and open it\n",
    "    path = '' + path + 'train_partition' + str(num) + '_data.json'\n",
    "    file = open(path)\n",
    "    \n",
    "    # Declare a tensor to hold the data, and a list to hold the labels.\n",
    "    # Dimensions: 0: length of the file. 1: the 33 fields in the data. 2: the 60 observations in each field. \n",
    "    # TODO: figure out the length of the file. \n",
    "    tnsr = torch.Tensor().new_empty((len(file), 33, 60), device=device)\n",
    "    labels = []\n",
    "    \n",
    "    # Legacy\n",
    "    train = []\n",
    "    \n",
    "#     # Track our place in the tensor\n",
    "#     i=-1\n",
    "    for line in file:\n",
    "#         # Increment where we are\n",
    "#         i += 1\n",
    "        # Legacy\n",
    "        if i > 2:\n",
    "            break\n",
    "        # Load the line as a dictionary. Row is an integer place and v is a smaller dictionary.\n",
    "        d: dict = json.loads(line)\n",
    "        for row, v in d.items():\n",
    "            # append the label to our list\n",
    "            labels.append(v['label'])\n",
    "            # Legacy\n",
    "            train.append(v['values'])\n",
    "            \n",
    "            # Break each individual dictionary into dictionaries of observations\n",
    "            # Key is the string in magDict, and timeDict is a dictionary of observations over time\n",
    "            for key, timeDict in v['values'].items():\n",
    "                # Turn our name string into a numeric value\n",
    "                location = magDict[key]\n",
    "                # Get the measurements out of the time series dictionary\n",
    "                for timeStamp, measurement in timeDict.items()\n",
    "                    tnsr[int(row)][location][int(timeStamp)] = measurement\n",
    "    # Close the file. I'm not a heathen\n",
    "    file.close()\n",
    "                    \n",
    "    # print(train1[0])\n",
    "\n",
    "    # All below here is legacy\n",
    "    j = -1\n",
    "    for k in train[0]:\n",
    "        l=0\n",
    "    #     print(len(train1[0].items()))\n",
    "        j +=1\n",
    "        print(\"'\", k, \"'\", ': ', j, sep='')\n",
    "    print(train[0]['EPSX'][f'{59}'])\n",
    "    return tnsr, labels\n",
    "\n",
    "train1 = getTrainData(1, 'cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
