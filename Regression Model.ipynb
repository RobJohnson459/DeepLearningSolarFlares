{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from normalizer import counter, subSample\n",
    "from torch.utils.data import DataLoader\n",
    "from normalizer import subSample, getDataFromJSON\n",
    "\n",
    "device = 'cpu' # Change this to cuda for GPU enabled computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading event 1/785\n",
      "Now loading event 101/785\n",
      "Now loading event 201/785\n",
      "Now loading event 301/785\n",
      "Now loading event 401/785\n",
      "Now loading event 501/785\n",
      "Now loading event 601/785\n",
      "Now loading event 701/785\n",
      "785 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "# This file has 77270 data points. 71633 do not have NAN values.\n",
    "# %time train1, labels1, weights1 = getDataFromJSON(path=\"data/train_partition1_data.json\", earlyStop=-1)\n",
    "train1, labels1 = subSample(\"data/train_partition1_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading event 1/300\n",
      "Now loading event 101/300\n",
      "Now loading event 201/300\n",
      "300 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "# This file has 93767 data points. 82425 of them do not have NAN values.  \n",
    "# %time train2, labels2, weights2 = getDataFromJSON(path=\"data/train_partition2_data.json\", earlyStop=-1)\n",
    "train2, labels2 = subSample(\"data/train_partition2_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading event 1/585\n",
      "Now loading event 101/585\n",
      "Now loading event 201/585\n",
      "Now loading event 301/585\n",
      "Now loading event 401/585\n",
      "Now loading event 501/585\n",
      "585 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "# This file has 42986 data points. 37759 of them do not have NAN values.  \n",
    "# %time train3, labels3, weights3 = getDataFromJSON(path=\"data/train_partition3_data.json\", earlyStop=-1)\n",
    "train3, labels3 = subSample(\"data/train_partition3_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.6095e+10, 5.6185e+10, 5.6320e+10, 5.6230e+10, 5.6633e+10, 5.6700e+10,\n",
       "        5.6721e+10, 5.7005e+10, 5.7128e+10, 5.7335e+10, 5.7524e+10, 5.7700e+10,\n",
       "        5.8026e+10, 5.8195e+10, 5.8293e+10, 5.8325e+10, 5.8458e+10, 5.8522e+10,\n",
       "        5.8599e+10, 5.8633e+10, 5.8895e+10, 5.9083e+10, 5.9160e+10, 5.9369e+10,\n",
       "        5.9312e+10, 5.9342e+10, 5.9696e+10, 5.9835e+10, 5.9866e+10, 6.0144e+10,\n",
       "        6.0255e+10, 6.0501e+10, 6.0554e+10, 6.0493e+10, 6.0774e+10, 6.0800e+10,\n",
       "        6.0813e+10, 6.0933e+10, 6.0885e+10, 6.1169e+10, 6.1346e+10, 6.1364e+10,\n",
       "        6.1599e+10, 6.1777e+10, 6.1715e+10, 6.1813e+10, 6.1773e+10, 6.1688e+10,\n",
       "        6.1471e+10, 6.1425e+10, 6.1285e+10, 6.1098e+10, 6.1073e+10, 6.0710e+10,\n",
       "        6.0641e+10, 6.0710e+10, 6.0857e+10, 6.0728e+10, 6.0693e+10, 6.0833e+10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3429.9802, 3444.6777, 3471.2712, 3477.1567, 3532.2834, 3470.6143,\n",
       "        3478.2695, 3563.7605, 3509.6221, 3600.8823, 3586.3240, 3607.0430,\n",
       "        3622.1245, 3583.2434, 3622.1433, 3645.5581, 3633.9895, 3682.0950,\n",
       "        3606.4170, 3668.0813, 3689.6143, 3671.8491, 3660.6914, 3659.5105,\n",
       "        3635.0242, 3653.2874, 3649.6904, 3647.1797, 3650.4246, 3620.0278,\n",
       "        3671.7280, 3710.4827, 3690.0315, 3678.0454, 3646.0427, 3624.6687,\n",
       "        3580.2256, 3626.6167, 3635.1226, 3618.3586, 3624.2644, 3622.0237,\n",
       "        3640.3481, 3644.0481, 3658.2900, 3701.5437, 3687.8821, 3662.8955,\n",
       "        3621.3562, 3651.4104, 3614.4851, 3563.1714, 3593.1545, 3526.1267,\n",
       "        3511.8232, 3512.1658, 3475.2561, 3489.1379, 3482.3259, 3494.7253])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network. Make sure to end with nn.Softmax activation\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNet\n",
    "\n",
    "class logRegWithHidden(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, num_classes=5, drop1=.5, input_size=1980):\n",
    "        super().__init__() \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layerout = nn.Linear(hidden_size2, num_classes)\n",
    "        #Define a RELU Activation unit\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.smax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(p=drop1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Forward Propagate through the layers as defined above\n",
    "        y = self.drop(x.reshape(-1, 1980))\n",
    "        y = self.drop(self.relu(self.layer1(y)))\n",
    "        y = self.relu(self.layer2(y))\n",
    "        y = self.smax(self.layerout(y))\n",
    "        return y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(modelModule, inputs, labels, weight, valSets, valLabels, valweight, *args, lr=0.01, **kwargs):\n",
    "    # TODO: Is this right? How do I determine the weights here?\n",
    "    \n",
    "    #TODO: does this work?\n",
    "    model = modelModule(*args, **kwargs)\n",
    "    print(model)\n",
    "    \n",
    "    if weight is not None: weight = torch.Tensor(weight)\n",
    "    lfc = nn.CrossEntropyLoss(weight=weight)\n",
    "#     valLabels = torch.tensor(valLabels, dtype=torch.int)\n",
    "    #ideas\n",
    "    # 1-(weight/np.sum(weight))\n",
    "    # .2/weight - this one normalizes so that each class is responsible for 20% of the loss\n",
    "    # 1/weight - this is a bit naive, but the classes with fewer items are weighted more.\n",
    "    # 1/(weight+1) - makes sure we don't have any pesky zeroes\n",
    "    # np.sum(weight)/weight if your learning rate is too low.\n",
    "    \n",
    "    # Hyperparameters\n",
    "    batch = 256\n",
    "    epochs = 4 # artificially low for debugging\n",
    "    \n",
    "    # Start a dataloader object\n",
    "    data = list(zip(inputs,labels))\n",
    "    val = list(zip(valSets,valLabels))\n",
    "    loader = DataLoader(data, batch_size = batch, num_workers=4)\n",
    "    valLoader = DataLoader(val, batch_size = int(len(val)/4), num_workers=4)\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    print(opt.state_dict())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        batch_loss = []\n",
    "        for (xtrain,ytrain) in loader:\n",
    "            opt.zero_grad()\n",
    "            print(opt.state_dict())\n",
    "            output = model(xtrain)\n",
    "            loss = lfc(output,ytrain)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            print(opt.state_dict())\n",
    "            print(model.state_dict())\n",
    "            opt.step()\n",
    "            print(opt.state_dict())\n",
    "            print('\\n\\n\\n\\n\\n')\n",
    "            batch_loss.append(loss.item())\n",
    "        print(f'The training loss for epoch {epoch+1}/{epochs} was {np.mean(batch_loss)}')\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        balanced = [[],[],[],[],[]]\n",
    "        batchLoss = []\n",
    "        unbalanced = []\n",
    "        \n",
    "        for (xval,yval) in valLoader:\n",
    "            output = model(xval)\n",
    "            loss = lfc(output,yval)\n",
    "            batchLoss.append(loss.item())\n",
    "            corrects = yval.clone().detach() == torch.argmax(output)\n",
    "            unbalanced.append(np.mean([1 if correct else 0 for correct in corrects.detach()]))\n",
    "            \n",
    "            for i, ans in enumerate(yval):\n",
    "                balanced[ans].append(corrects[i])\n",
    "        \n",
    "        balanced = [np.mean(i) for i in balanced]\n",
    "        balancedAccuracy = np.mean(balanced)\n",
    "        \n",
    "#         print(f'The total balanced accuracy for validation was {balancedAccuracy}')\n",
    "        print(f'The validation loss was :   {epoch+1}/{epochs} was {np.mean(batchLoss)}')\n",
    "        print(f'The unbalanced validation accuracy is {np.mean(unbalanced)}')\n",
    "        print(f'The accuracy for each is {balanced}')           \n",
    "    print(opt.state_dict())\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logRegWithHidden(\n",
      "  (layer1): Linear(in_features=1980, out_features=16384, bias=True)\n",
      "  (layer2): Linear(in_features=16384, out_features=8192, bias=True)\n",
      "  (layerout): Linear(in_features=8192, out_features=5, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (smax): Softmax(dim=1)\n",
      "  (drop): Dropout(p=0, inplace=False)\n",
      ")\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7486, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7017, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7134, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7525, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.8229, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The training loss for epoch 1/4 was 1.747817873954773\n",
      "The validation loss was :   1/4 was 1.7719547986984252\n",
      "The unbalanced validation accuracy is 0.16027397260273973\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7486, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7017, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7134, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7525, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.8229, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The training loss for epoch 2/4 was 1.747817873954773\n",
      "The validation loss was :   2/4 was 1.7719547986984252\n",
      "The unbalanced validation accuracy is 0.16027397260273973\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7486, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7017, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7134, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7525, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.8229, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The training loss for epoch 3/4 was 1.747817873954773\n",
      "The validation loss was :   3/4 was 1.7719547986984252\n",
      "The unbalanced validation accuracy is 0.16027397260273973\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7486, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7017, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7134, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.7525, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "tensor(1.8229, grad_fn=<NllLossBackward>)\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "OrderedDict([('layer1.weight', tensor([[ 0.0212, -0.0120, -0.0093,  ..., -0.0019,  0.0122, -0.0064],\n",
      "        [-0.0068,  0.0139, -0.0138,  ...,  0.0221,  0.0052,  0.0165],\n",
      "        [-0.0040,  0.0107, -0.0039,  ...,  0.0196,  0.0137, -0.0164],\n",
      "        ...,\n",
      "        [ 0.0103, -0.0109, -0.0224,  ..., -0.0217, -0.0204,  0.0208],\n",
      "        [-0.0167, -0.0073, -0.0204,  ...,  0.0025, -0.0036, -0.0052],\n",
      "        [-0.0050,  0.0069, -0.0035,  ..., -0.0029,  0.0167,  0.0071]])), ('layer1.bias', tensor([-0.0222, -0.0181, -0.0003,  ..., -0.0207, -0.0166, -0.0159])), ('layer2.weight', tensor([[-0.0022,  0.0018,  0.0007,  ..., -0.0024, -0.0041, -0.0026],\n",
      "        [-0.0077,  0.0010, -0.0052,  ..., -0.0010,  0.0042, -0.0039],\n",
      "        [-0.0053,  0.0035,  0.0007,  ..., -0.0052, -0.0050, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0063,  0.0048, -0.0017,  ..., -0.0067,  0.0076,  0.0056],\n",
      "        [ 0.0018, -0.0030, -0.0059,  ..., -0.0057,  0.0020,  0.0044],\n",
      "        [-0.0045,  0.0062,  0.0018,  ..., -0.0072,  0.0061, -0.0027]])), ('layer2.bias', tensor([-0.0031, -0.0020,  0.0044,  ...,  0.0015, -0.0019, -0.0077])), ('layerout.weight', tensor([[-0.0031, -0.0077,  0.0050,  ...,  0.0104,  0.0078, -0.0038],\n",
      "        [ 0.0079, -0.0096,  0.0102,  ..., -0.0051, -0.0053, -0.0102],\n",
      "        [-0.0061, -0.0092,  0.0032,  ..., -0.0012,  0.0066, -0.0056],\n",
      "        [-0.0009, -0.0006,  0.0012,  ...,  0.0002, -0.0002,  0.0045],\n",
      "        [-0.0076,  0.0012,  0.0022,  ...,  0.0010,  0.0047,  0.0004]])), ('layerout.bias', tensor([ 0.0025, -0.0039, -0.0109, -0.0036,  0.0062]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The training loss for epoch 4/4 was 1.747817873954773\n",
      "The validation loss was :   4/4 was 1.7719547986984252\n",
      "The unbalanced validation accuracy is 0.16027397260273973\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "{'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "CPU times: user 1min 9s, sys: 10.3 s, total: 1min 19s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "# [weights1[i] + weights2[i] for i in range(5)]\n",
    "%time newModel = train(logRegWithHidden, torch.cat((train1, train2), dim=0), labels1 + labels2, None, train3, labels3, None, 4096*4, 2048*4, lr = 0.1, drop1=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1 # choose this to check the sth layer\n",
    "feature_extraction1 = [child for child in model.children()]\n",
    "print(feature_extraction1[s])\n",
    "feature_extraction2 = [child for child in newModel.children()]\n",
    "print(feature_extraction2[s])\n",
    "print(torch.max(feature_extraction1[s].weight - feature_extraction2[s].weight).detach())\n",
    "print(torch.min(feature_extraction1[s].weight - feature_extraction2[s].weight).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train(\n",
    "    model,\n",
    "    torch.cat((train1, train3), dim=0),\n",
    "    labels1 + labels3,\n",
    "    None,\n",
    "    train2,\n",
    "    labels2,\n",
    "    None,\n",
    "    lr = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train(\n",
    "    model,\n",
    "    torch.cat((train3, train2), dim=0),\n",
    "    labels3 + labels2,\n",
    "    None,\n",
    "    train1,\n",
    "    labels1,\n",
    "    None,\n",
    "    lr = 0.00000001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
