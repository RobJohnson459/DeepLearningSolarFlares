{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't have the data, download it\n",
    "!wget https://dmlab.cs.gsu.edu/solar/data/data-comp-2020/train_partition1_data.json\n",
    "!mkdir data\n",
    "!mv train_partition1_data.json data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from normalizer import counter, subSample\n",
    "from torch.utils.data import DataLoader\n",
    "from normalizer import subSample, getDataFromJSON\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # Change this to cuda for GPU enabled computers\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition1_data.json\n",
      "Now loading event 1/785\n",
      "Now loading event 101/785\n",
      "Now loading event 201/785\n",
      "Now loading event 301/785\n",
      "Now loading event 401/785\n",
      "Now loading event 501/785\n",
      "Now loading event 601/785\n",
      "Now loading event 701/785\n",
      "785 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "train1, labels1 = subSample(\"data/train_partition1_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in [train1]: # This line edited for easier loading\n",
    "    for i in range(X.shape[1]): # the number of types of measurements\n",
    "        min_x = torch.min(X[:,i,:])\n",
    "        X[:,i,:] -= min_x\n",
    "        X[:,i,:] /= torch.max(X[:,i,:]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network. Make sure to end with nn.Softmax activation\n",
    "import torch.nn as nn\n",
    "# from skorch import NeuralNet\n",
    "\n",
    "class logRegWithHidden(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, num_classes=5, drop1=.5, input_size=1980):\n",
    "        super().__init__() \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layerout = nn.Linear(hidden_size2, num_classes)\n",
    "        #Define a RELU Activation unit\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.smax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(p=drop1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Forward Propagate through the layers as defined above\n",
    "        y = self.drop(x.reshape(-1, 1980))\n",
    "        y = self.drop(self.relu(self.layer1(y)))\n",
    "        y = self.relu(self.layer2(y))\n",
    "        y = self.layerout(y)\n",
    "        y = self.smax(y)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(modelModule, inputs, labels, weight, valSets, valLabels, valweight, *modelArgs, lr=0.01, **modelKwargs):\n",
    "    \n",
    "    # modify these variables to control how much is printed\n",
    "    pmodel = False\n",
    "    pstateDict = False\n",
    "    pindvLoss = False\n",
    "    pmodelDict = False\n",
    "    pvalOut = False\n",
    "    \n",
    "    \n",
    "    #TODO: does this work?\n",
    "    model = modelModule(*modelArgs, **modelKwargs)\n",
    "    if pmodel: print(model)\n",
    "    \n",
    "    if weight is not None: weight = torch.Tensor(weight)\n",
    "    lfc = nn.CrossEntropyLoss(weight=weight)\n",
    "#     valLabels = torch.tensor(valLabels, dtype=torch.int)\n",
    "    #ideas\n",
    "    # 1-(weight/np.sum(weight))\n",
    "    # .2/weight - this one normalizes so that each class is responsible for 20% of the loss\n",
    "    # 1/weight - this is a bit naive, but the classes with fewer items are weighted more.\n",
    "    # 1/(weight+1) - makes sure we don't have any pesky zeroes\n",
    "    # np.sum(weight)/weight if your learning rate is too low.\n",
    "    \n",
    "    # Hyperparameters\n",
    "    batch = 256\n",
    "    epochs = 4 # artificially low for debugging\n",
    "    \n",
    "    # Start a dataloader object\n",
    "    data = list(zip(inputs,labels))\n",
    "    val = list(zip(valSets,valLabels))\n",
    "    loader = DataLoader(data, batch_size = batch, num_workers=4)\n",
    "    valLoader = DataLoader(val, batch_size = int(len(val)/4), num_workers=4)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    if pstateDict: print(opt.state_dict())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        batch_loss = []\n",
    "        for (xtrain,ytrain) in loader:\n",
    "            opt.zero_grad()\n",
    "            if pstateDict: print(opt.state_dict())\n",
    "            output = model(xtrain)\n",
    "            loss = lfc(output,ytrain)\n",
    "            if pindvLoss: print(loss)\n",
    "            loss.backward()\n",
    "            if pstateDict: print(opt.state_dict())\n",
    "            if pmodelDict: print(model.state_dict())\n",
    "            opt.step()\n",
    "            if pstateDict: print(opt.state_dict())\n",
    "            if pstateDict or pmodelDict: print('\\n\\n\\n\\n\\n')\n",
    "            batch_loss.append(loss.item())\n",
    "        print(f'The training loss for epoch {epoch+1}/{epochs} was {np.mean(batch_loss)}')\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        balanced = [[],[],[],[],[]]\n",
    "        batchLoss = []\n",
    "        unbalanced = []\n",
    "        \n",
    "        for (xval,yval) in valLoader:\n",
    "            output = model(xval)\n",
    "            loss = lfc(output,yval)\n",
    "            batchLoss.append(loss.item())\n",
    "            if pvalOut : print(output)\n",
    "            corrects = yval.clone().detach() == torch.argmax(output,1)\n",
    "            if pvalOut: print(yval.clone().detach(), torch.argmax(output,1))\n",
    "            if pvalOut: print(corrects.detach())\n",
    "            if pvalOut: print('===========================\\n\\n\\n')\n",
    "            unbalanced.append(np.mean([1 if correct else 0 for correct in corrects.detach()]))\n",
    "            \n",
    "            for i, ans in enumerate(yval):\n",
    "                balanced[ans].append(corrects[i])\n",
    "        \n",
    "        balanced = [np.mean(i) for i in balanced]\n",
    "        balancedAccuracy = np.mean(balanced)\n",
    "        \n",
    "#         print(f'The total balanced accuracy for validation was {balancedAccuracy}')\n",
    "        print(f'The values of unbalanced are {unbalanced}')\n",
    "        print(f'The validation loss was :   {epoch+1}/{epochs} was {np.mean(batchLoss)}')\n",
    "        print(f'The unbalanced validation accuracy is {np.mean(unbalanced)}')\n",
    "        print(f'The accuracy for each is {balanced}')           \n",
    "    print(opt.state_dict())\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/4 was 1.6757709085941315\n",
      "The values of unbalanced are [0.20408163265306123, 0.25510204081632654, 0.16326530612244897, 0.17857142857142858, 0.0]\n",
      "The validation loss was :   1/4 was 1.7446301937103272\n",
      "The unbalanced validation accuracy is 0.16020408163265307\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "The training loss for epoch 2/4 was 1.7240572571754456\n",
      "The values of unbalanced are [0.20408163265306123, 0.25510204081632654, 0.16326530612244897, 0.17857142857142858, 0.0]\n",
      "The validation loss was :   2/4 was 1.7446301937103272\n",
      "The unbalanced validation accuracy is 0.16020408163265307\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "The training loss for epoch 3/4 was 1.7240572571754456\n",
      "The values of unbalanced are [0.20408163265306123, 0.25510204081632654, 0.16326530612244897, 0.17857142857142858, 0.0]\n",
      "The validation loss was :   3/4 was 1.7446301937103272\n",
      "The unbalanced validation accuracy is 0.16020408163265307\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "The training loss for epoch 4/4 was 1.7240572571754456\n",
      "The values of unbalanced are [0.20408163265306123, 0.25510204081632654, 0.16326530612244897, 0.17857142857142858, 0.0]\n",
      "The validation loss was :   4/4 was 1.7446301937103272\n",
      "The unbalanced validation accuracy is 0.16020408163265307\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "{'state': {0: {'step': 16, 'exp_avg': tensor([[-1.7289e-08, -1.7330e-08, -1.7447e-08,  ..., -2.1965e-08,\n",
      "         -2.1965e-08, -2.1965e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.4813e-07, -2.4961e-07, -2.4952e-07,  ..., -3.0241e-07,\n",
      "         -3.0241e-07, -3.0241e-07],\n",
      "        [ 2.5192e-07,  2.5636e-07,  2.5748e-07,  ...,  6.1818e-07,\n",
      "          5.9295e-07,  5.9295e-07]]), 'exp_avg_sq': tensor([[6.9458e-16, 6.9781e-16, 7.0725e-16,  ..., 9.7221e-16, 9.7221e-16,\n",
      "         9.7221e-16],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.4307e-13, 1.4479e-13, 1.4468e-13,  ..., 2.1281e-13, 2.1281e-13,\n",
      "         2.1281e-13],\n",
      "        [1.4748e-13, 1.5272e-13, 1.5406e-13,  ..., 8.8804e-13, 8.1705e-13,\n",
      "         8.1705e-13]])}, 1: {'step': 16, 'exp_avg': tensor([-2.1965e-08,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "        -3.4721e-07,  6.1510e-07]), 'exp_avg_sq': tensor([9.7221e-16, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 2.8050e-13,\n",
      "        8.7924e-13])}, 2: {'step': 16, 'exp_avg': tensor([[-3.6141e-09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -5.9360e-10, -1.2027e-08],\n",
      "        [-1.0148e-08,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          8.9433e-09, -4.3225e-07],\n",
      "        [-2.4825e-09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          6.3915e-10, -8.6640e-08],\n",
      "        ...,\n",
      "        [ 1.3769e-10,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          2.2288e-10, -5.3409e-08],\n",
      "        [-8.4775e-08,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -8.4568e-10,  4.8218e-07],\n",
      "        [-4.7909e-09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          3.2313e-09, -1.9570e-07]]), 'exp_avg_sq': tensor([[2.4759e-17, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 6.6391e-19,\n",
      "         3.3616e-16],\n",
      "        [2.4670e-16, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.7573e-16,\n",
      "         4.3419e-13],\n",
      "        [1.9532e-17, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 7.6972e-19,\n",
      "         1.7444e-14],\n",
      "        ...,\n",
      "        [3.5721e-20, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 9.3602e-20,\n",
      "         6.6289e-15],\n",
      "        [1.6496e-14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.3475e-18,\n",
      "         5.4029e-13],\n",
      "        [6.1869e-17, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.6960e-17,\n",
      "         8.8999e-14]])}, 3: {'step': 16, 'exp_avg': tensor([-1.1303e-07, -1.0353e-06, -4.3902e-07,  ..., -1.7998e-07,\n",
      "        -1.3031e-06, -7.3994e-07]), 'exp_avg_sq': tensor([2.9630e-14, 2.4908e-12, 4.4814e-13,  ..., 7.5315e-14, 3.9448e-12,\n",
      "        1.2727e-12])}, 4: {'step': 16, 'exp_avg': tensor([[ 9.9811e-07, -1.2802e-05,  7.6820e-07,  ...,  1.1700e-06,\n",
      "          2.9884e-06, -4.6409e-05],\n",
      "        [ 8.2973e-08,  1.5651e-05,  4.3664e-08,  ...,  3.3196e-07,\n",
      "          1.0078e-05, -2.7109e-06],\n",
      "        [ 1.5079e-08, -4.2473e-06,  4.0956e-08,  ...,  3.7011e-08,\n",
      "         -2.7693e-06, -6.6066e-06],\n",
      "        [ 7.8973e-08,  9.7136e-06,  3.8759e-08,  ..., -8.0996e-07,\n",
      "         -4.5001e-06,  1.2192e-05],\n",
      "        [-1.1753e-06, -8.3161e-06, -8.9177e-07,  ..., -7.2919e-07,\n",
      "         -5.7968e-06,  4.3535e-05]]), 'exp_avg_sq': tensor([[1.6147e-12, 4.1102e-10, 1.7167e-12,  ..., 1.6494e-12, 1.9017e-11,\n",
      "         5.1794e-09],\n",
      "        [1.5998e-14, 5.6927e-10, 4.4305e-15,  ..., 2.5608e-13, 2.3601e-10,\n",
      "         1.7078e-11],\n",
      "        [5.2840e-16, 4.1922e-11, 3.8980e-15,  ..., 3.1833e-15, 1.7822e-11,\n",
      "         1.0143e-10],\n",
      "        [1.4493e-14, 2.1926e-10, 3.4911e-15,  ..., 1.5245e-12, 4.7059e-11,\n",
      "         3.4541e-10],\n",
      "        [1.7509e-12, 1.4277e-10, 1.6564e-12,  ..., 1.5021e-12, 7.4650e-11,\n",
      "         4.5680e-09]])}, 5: {'step': 16, 'exp_avg': tensor([-9.8436e-05,  1.2602e-04, -7.9794e-05,  1.0459e-04, -5.2387e-05]), 'exp_avg_sq': tensor([2.2520e-08, 3.6907e-08, 1.4796e-08, 2.5423e-08, 6.3763e-09])}}, 'param_groups': [{'lr': 0.01, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5]}]}\n",
      "CPU times: user 2min 8s, sys: 28.4 s, total: 2min 37s\n",
      "Wall time: 41.3 s\n"
     ]
    }
   ],
   "source": [
    "# [weights1[i] + weights2[i] for i in range(5)]\n",
    "trainArgs = [logRegWithHidden, train1, labels1, None, train1, labels1, None]\n",
    "modelArgs = [4096*4, 2048*4]\n",
    "%time newModel = train(*trainArgs, *modelArgs, lr = 0.01, drop1=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
