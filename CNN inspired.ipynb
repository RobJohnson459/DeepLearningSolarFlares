{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robjohnson/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from normalizer import counter\n",
    "from torch.utils.data import DataLoader\n",
    "from normalizer import getDataFromJSON, subSample, trainer, tester, getTotalAccuracy, cfvalidation\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNet\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition1_data.json\n",
      "Now loading event 1/785\n",
      "Now loading event 101/785\n",
      "Now loading event 201/785\n",
      "Now loading event 301/785\n",
      "Now loading event 401/785\n",
      "Now loading event 501/785\n",
      "Now loading event 601/785\n",
      "Now loading event 701/785\n",
      "785 lines loaded.\n",
      "CPU times: user 20.9 s, sys: 1.82 s, total: 22.7 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "# This file has 77270 data points. \n",
    "%time train1, labels1 = subSample(path=\"data/train_partition1_data.json\", earlyStop=10000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition2_data.json\n",
      "Now loading event 1/300\n",
      "Now loading event 101/300\n",
      "Now loading event 201/300\n",
      "300 lines loaded.\n",
      "CPU times: user 17.1 s, sys: 2.28 s, total: 19.4 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "# This file has 93767 data points. \n",
    "%time train2, labels2 = subSample(path=\"data/train_partition2_data.json\", earlyStop=10000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition3_data.json\n",
      "Now loading event 1/585\n",
      "Now loading event 101/585\n",
      "Now loading event 201/585\n",
      "Now loading event 301/585\n",
      "Now loading event 401/585\n",
      "Now loading event 501/585\n",
      "585 lines loaded.\n",
      "CPU times: user 13.6 s, sys: 948 ms, total: 14.5 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "# This file has 42986 data points. \n",
    "%time train3, labels3 = subSample(path=\"data/train_partition3_data.json\", earlyStop=10000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2276, 0.2299, 0.2297, 0.2289, 0.2352, 0.2320, 0.2322, 0.2785, 0.2814,\n",
       "        0.2332, 0.2302, 0.2265, 0.2242, 0.2219, 0.2189, 0.2208, 0.2201, 0.2190,\n",
       "        0.2221, 0.2199, 0.2218, 0.2223, 0.2240, 0.2239, 0.2226, 0.2229, 0.2243,\n",
       "        0.2249, 0.2246, 0.2248, 0.2239, 0.2244, 0.2278, 0.2291, 0.2274, 0.2281,\n",
       "        0.2255, 0.2249, 0.2246, 0.2205, 0.2238, 0.2227, 0.2196, 0.2201, 0.2216,\n",
       "        0.2172, 0.2197, 0.2194, 0.2202, 0.2172, 0.2154, 0.2151, 0.2128, 0.2133,\n",
       "        0.2096, 0.2093, 0.2109, 0.2134, 0.2117, 0.2134])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network ##\n",
    "\n",
    "This network has two parts - the stack and the fully connected layers. The stack interprets a given measurement and then outputs from 60 to a given number of entries. The fully connected part then makes a prediction off of all of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a network that takes each individual time series as input and outputs an nx33 tensor\n",
    "\n",
    "class stack(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__() \n",
    "        self.n = n\n",
    "        self.layer00 = nn.Linear(60,n)\n",
    "        self.layer01 = nn.Linear(60,n)\n",
    "        self.layer02 = nn.Linear(60,n)\n",
    "        self.layer03 = nn.Linear(60,n)\n",
    "        self.layer04 = nn.Linear(60,n)\n",
    "        self.layer05 = nn.Linear(60,n)\n",
    "        self.layer06 = nn.Linear(60,n)\n",
    "        self.layer07 = nn.Linear(60,n)\n",
    "        self.layer08 = nn.Linear(60,n)\n",
    "        self.layer09 = nn.Linear(60,n)\n",
    "        self.layer10 = nn.Linear(60,n)\n",
    "        self.layer11 = nn.Linear(60,n)\n",
    "        self.layer12 = nn.Linear(60,n)\n",
    "        self.layer13 = nn.Linear(60,n)\n",
    "        self.layer14 = nn.Linear(60,n)\n",
    "        self.layer15 = nn.Linear(60,n)\n",
    "        self.layer16 = nn.Linear(60,n)\n",
    "        self.layer17 = nn.Linear(60,n)\n",
    "        self.layer18 = nn.Linear(60,n)\n",
    "        self.layer19 = nn.Linear(60,n)\n",
    "        self.layer20 = nn.Linear(60,n)\n",
    "        self.layer21 = nn.Linear(60,n)\n",
    "        self.layer22 = nn.Linear(60,n)\n",
    "        self.layer23 = nn.Linear(60,n)\n",
    "        self.layer24 = nn.Linear(60,n)\n",
    "        self.layer25 = nn.Linear(60,n)\n",
    "        self.layer26 = nn.Linear(60,n)\n",
    "        self.layer27 = nn.Linear(60,n)\n",
    "        self.layer28 = nn.Linear(60,n)\n",
    "        self.layer29 = nn.Linear(60,n)\n",
    "        self.layer30 = nn.Linear(60,n)\n",
    "        self.layer31 = nn.Linear(60,n)\n",
    "        self.layer32 = nn.Linear(60,n)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.zeros(x.shape[0], 33, self.n)\n",
    "        output[:,0,:] = self.layer00(x[:,0,:])\n",
    "        output[:,1,:] = self.layer01(x[:,1,:])\n",
    "        output[:,2,:] = self.layer02(x[:,2,:])\n",
    "        output[:,3,:] = self.layer03(x[:,3,:])\n",
    "        output[:,4,:] = self.layer04(x[:,4,:])\n",
    "        output[:,5,:] = self.layer05(x[:,5,:])\n",
    "        output[:,6,:] = self.layer06(x[:,6,:])\n",
    "        output[:,7,:] = self.layer07(x[:,7,:])\n",
    "        output[:,8,:] = self.layer08(x[:,8,:])\n",
    "        output[:,9,:] = self.layer09(x[:,9,:])\n",
    "        \n",
    "        output[:,10,:] = self.layer00(x[:,10,:])\n",
    "        output[:,11,:] = self.layer00(x[:,11,:])\n",
    "        output[:,12,:] = self.layer00(x[:,12,:])\n",
    "        output[:,13,:] = self.layer00(x[:,13,:])\n",
    "        output[:,14,:] = self.layer00(x[:,14,:])\n",
    "        output[:,15,:] = self.layer00(x[:,15,:])\n",
    "        output[:,16,:] = self.layer00(x[:,16,:])\n",
    "        output[:,17,:] = self.layer00(x[:,17,:])\n",
    "        output[:,18,:] = self.layer00(x[:,18,:])\n",
    "        output[:,19,:] = self.layer00(x[:,19,:])\n",
    "        \n",
    "        output[:,20,:] = self.layer00(x[:,20,:])\n",
    "        output[:,21,:] = self.layer00(x[:,21,:])\n",
    "        output[:,22,:] = self.layer00(x[:,22,:])\n",
    "        output[:,23,:] = self.layer00(x[:,23,:])\n",
    "        output[:,24,:] = self.layer00(x[:,24,:])\n",
    "        output[:,25,:] = self.layer00(x[:,25,:])\n",
    "        output[:,26,:] = self.layer00(x[:,26,:])\n",
    "        output[:,27,:] = self.layer00(x[:,27,:])\n",
    "        output[:,28,:] = self.layer00(x[:,28,:])\n",
    "        output[:,29,:] = self.layer00(x[:,29,:])\n",
    "        \n",
    "        output[:,30,:] = self.layer00(x[:,30,:])\n",
    "        output[:,31,:] = self.layer00(x[:,31,:])\n",
    "        output[:,32,:] = self.layer00(x[:,32,:])\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network. Make sure to end with nn.Softmax activation    \n",
    "    \n",
    "class CNNinspired(nn.Module):\n",
    "    def __init__(self, n, hidden_size, num_classes=5, drop1=.5):\n",
    "        super().__init__() \n",
    "        self.n = n\n",
    "        self.layer1 = stack(n)\n",
    "        self.layer2 = nn.Linear(n*33, hidden_size)\n",
    "        self.layerout = nn.Linear(hidden_size, num_classes)\n",
    "        #Define a RELU Activation unit\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.smax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(p=drop1)\n",
    "        self.b = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Forward Propagate through the layers as defined above\n",
    "        output = self.layer1(x)\n",
    "        if self.b:\n",
    "            self.out = output\n",
    "            self.b = False\n",
    "#         print(x.shape)\n",
    "#         print('This is iffy')\n",
    "#         print(output.shape)\n",
    "#         assert False\n",
    "        y = self.sig( output.reshape(-1, 33*self.n))\n",
    "        y = self.relu(self.layer2(y))\n",
    "        y = self.smax(self.layerout(y))\n",
    "        return y \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin testing with three fold validation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelArgs = [3, 128]\n",
    "modelKwargs = {'drop1':.25}\n",
    "trainKwargs = {'epochs':50, 'lr' : 0.01}\n",
    "# Attempted learing rates: \n",
    "# 0.00001 - one in a million change\n",
    "# 0.000001 - one in 10 million\n",
    "# 0.0001 - one in 100 thousand\n",
    "# 0.001 with 128 hidden neurons instead of 30 - one in 10 thousand\n",
    "\n",
    "    # model1 = CNNinspired(1, 30)\n",
    "    # model3 = CNNinspired(3, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/50 was 1.6093676020117367\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   1/50 was 1.6092851223089757\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 2/50 was 1.609345842810238\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   2/50 was 1.609263818895715\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 3/50 was 1.6093250092338114\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   3/50 was 1.6092432657877604\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 4/50 was 1.6093051503686344\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   4/50 was 1.6092229276640801\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 5/50 was 1.6092859506607056\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   5/50 was 1.6092032512029013\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 6/50 was 1.6092670244329117\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   6/50 was 1.6091840136764395\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 7/50 was 1.6092484768699198\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   7/50 was 1.6091649960248897\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 8/50 was 1.6092302308363073\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   8/50 was 1.6091462612152099\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 9/50 was 1.6092122793197632\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   9/50 was 1.6091277479106545\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 10/50 was 1.6091945942710428\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   10/50 was 1.609109410465273\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 11/50 was 1.6091770705054789\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   11/50 was 1.6090912423582158\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 12/50 was 1.609159834244672\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   12/50 was 1.609073291069422\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 13/50 was 1.6091425769469316\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   13/50 was 1.609055506469857\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 14/50 was 1.6091256842893713\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   14/50 was 1.6090380477090167\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 15/50 was 1.6091086794348324\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   15/50 was 1.6090207014328395\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 16/50 was 1.6090919410481173\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   16/50 was 1.6090034851661095\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 17/50 was 1.6090753008337582\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   17/50 was 1.6089863620252691\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 18/50 was 1.6090587517794441\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   18/50 was 1.6089692570205427\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 19/50 was 1.6090423079097973\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   19/50 was 1.608952219873412\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 20/50 was 1.6090258289785946\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   20/50 was 1.6089351615335188\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 21/50 was 1.6090093851089478\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   21/50 was 1.6089180663100675\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 22/50 was 1.608992906177745\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   22/50 was 1.6089009735319348\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 23/50 was 1.608976497369654\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   23/50 was 1.6088838974634807\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 24/50 was 1.6089600815492517\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   24/50 was 1.6088667965342855\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 25/50 was 1.6089436166426714\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   25/50 was 1.608849717409183\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 26/50 was 1.6089270465514238\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   26/50 was 1.6088325798002063\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 27/50 was 1.6089104694478653\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   27/50 was 1.6088153307254498\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 28/50 was 1.608894004541285\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   28/50 was 1.6087980413029337\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 29/50 was 1.6088772100560806\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   29/50 was 1.6087805754099136\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 30/50 was 1.6088604646570541\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   30/50 was 1.6087629947906885\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 31/50 was 1.6088436140733606\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   31/50 was 1.6087452201761752\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 32/50 was 1.6088267494650448\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   32/50 was 1.608727438429482\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 33/50 was 1.6088096604627722\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   33/50 was 1.6087095089447805\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 34/50 was 1.6087924873127657\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   34/50 was 1.608691430091858\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 35/50 was 1.6087751248303581\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   35/50 was 1.6086731853648129\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 36/50 was 1.6087575870401718\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   36/50 was 1.6086547863789094\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.9914529914529915, 0.008547008547008548]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 37/50 was 1.6087399300406962\n",
      "The total balanced accuracy for validation was 0.19145299145299144\n",
      "The validation loss was :   37/50 was 1.6086361298194298\n",
      "The unbalanced validation accuracy is 0.19145299145299147\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.9487179487179487, 0.008547008547008548]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 38/50 was 1.6087221398073084\n",
      "The total balanced accuracy for validation was 0.19145299145299147\n",
      "The validation loss was :   38/50 was 1.6086173803378374\n",
      "The unbalanced validation accuracy is 0.19145299145299147\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.9316239316239316, 0.02564102564102564]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 39/50 was 1.6087040059706743\n",
      "The total balanced accuracy for validation was 0.1982905982905983\n",
      "The validation loss was :   39/50 was 1.6085984340080848\n",
      "The unbalanced validation accuracy is 0.19829059829059828\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.9230769230769231, 0.06837606837606838]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 40/50 was 1.6086858651217293\n",
      "The total balanced accuracy for validation was 0.1982905982905983\n",
      "The validation loss was :   40/50 was 1.6085792447766687\n",
      "The unbalanced validation accuracy is 0.19829059829059828\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.8461538461538461, 0.1452991452991453]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 41/50 was 1.6086674718295826\n",
      "The total balanced accuracy for validation was 0.1965811965811966\n",
      "The validation loss was :   41/50 was 1.6085599353170803\n",
      "The unbalanced validation accuracy is 0.19658119658119658\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.7435897435897436, 0.23931623931623933]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 42/50 was 1.6086488751804127\n",
      "The total balanced accuracy for validation was 0.20341880341880342\n",
      "The validation loss was :   42/50 was 1.6085403750085423\n",
      "The unbalanced validation accuracy is 0.20341880341880342\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.6410256410256411, 0.37606837606837606]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 43/50 was 1.6086300821865307\n",
      "The total balanced accuracy for validation was 0.21709401709401713\n",
      "The validation loss was :   43/50 was 1.608520612349877\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.5555555555555556, 0.5299145299145299]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 44/50 was 1.6086108614416683\n",
      "The total balanced accuracy for validation was 0.2341880341880342\n",
      "The validation loss was :   44/50 was 1.608500665680975\n",
      "The unbalanced validation accuracy is 0.2341880341880342\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.48717948717948717, 0.6837606837606838]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 45/50 was 1.608591549536761\n",
      "The total balanced accuracy for validation was 0.24273504273504276\n",
      "The validation loss was :   45/50 was 1.6084804787595048\n",
      "The unbalanced validation accuracy is 0.24273504273504273\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.41025641025641024, 0.8034188034188035]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 46/50 was 1.6085719290901632\n",
      "The total balanced accuracy for validation was 0.2358974358974359\n",
      "The validation loss was :   46/50 was 1.608459957033141\n",
      "The unbalanced validation accuracy is 0.2358974358974359\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.3162393162393162, 0.8632478632478633]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 47/50 was 1.608552000101875\n",
      "The total balanced accuracy for validation was 0.22735042735042735\n",
      "The validation loss was :   47/50 was 1.6084391626537355\n",
      "The unbalanced validation accuracy is 0.22735042735042735\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.23931623931623933, 0.8974358974358975]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 48/50 was 1.608531860744252\n",
      "The total balanced accuracy for validation was 0.21880341880341883\n",
      "The validation loss was :   48/50 was 1.6084180919533102\n",
      "The unbalanced validation accuracy is 0.2188034188034188\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.17094017094017094, 0.9230769230769231]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 49/50 was 1.6085112165002262\n",
      "The total balanced accuracy for validation was 0.21025641025641026\n",
      "The validation loss was :   49/50 was 1.6083967341317071\n",
      "The unbalanced validation accuracy is 0.21025641025641026\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.09401709401709402, 0.9572649572649573]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 50/50 was 1.608490228652954\n",
      "The total balanced accuracy for validation was 0.20341880341880342\n",
      "The validation loss was :   50/50 was 1.6083750366145728\n",
      "The unbalanced validation accuracy is 0.20341880341880342\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 0.042735042735042736, 0.9743589743589743]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 5.56 s, total: 1min 19s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "train1Args = [CNNinspired, torch.cat((train1, train2), dim=0), labels1 + labels2, None, train3, labels3, None]\n",
    "%time train12 = trainer(*train1Args, *modelArgs, **trainKwargs, **modelKwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/50 was 1.6097854538397356\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   1/50 was 1.6094883894920349\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 2/50 was 1.6096908775242893\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   2/50 was 1.6093925289312998\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 3/50 was 1.6095940308137373\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   3/50 was 1.6093101998170216\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 4/50 was 1.6095119010318408\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   4/50 was 1.609241732756297\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 5/50 was 1.609442949295044\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   5/50 was 1.6091794208685557\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 6/50 was 1.609378917650743\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   6/50 was 1.609121036529541\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 7/50 was 1.609318500215357\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   7/50 was 1.6090658632914225\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 8/50 was 1.609261160547083\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   8/50 was 1.6090134942531586\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 9/50 was 1.609206410971555\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   9/50 was 1.6089635181427002\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 10/50 was 1.6091538288376548\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   10/50 was 1.6089156524340311\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 11/50 was 1.6091032407500527\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   11/50 was 1.608869743347168\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 12/50 was 1.6090546250343323\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   12/50 was 1.60882555325826\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 13/50 was 1.609007483178919\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   13/50 was 1.6087827344735464\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 14/50 was 1.608961826021021\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   14/50 was 1.6087412230173748\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 15/50 was 1.6089177836071362\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   15/50 was 1.6087009302775066\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 16/50 was 1.608874727379192\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   16/50 was 1.6086615653832754\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 17/50 was 1.6088326302441684\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   17/50 was 1.6086232848962148\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 18/50 was 1.6087917577136646\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   18/50 was 1.6085852376619976\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 19/50 was 1.6087516166947105\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   19/50 was 1.6085477757453919\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 20/50 was 1.6087123589082197\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   20/50 was 1.6085108546415965\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 21/50 was 1.6086738597262988\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   21/50 was 1.6084744413693746\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 22/50 was 1.6086358482187444\n",
      "The total balanced accuracy for validation was 0.22333333333333333\n",
      "The validation loss was :   22/50 was 1.6084384445349376\n",
      "The unbalanced validation accuracy is 0.22333333333333333\n",
      "The accuracy for each is [0.11666666666666667, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 23/50 was 1.608598373152993\n",
      "The total balanced accuracy for validation was 0.23333333333333334\n",
      "The validation loss was :   23/50 was 1.6084027687708538\n",
      "The unbalanced validation accuracy is 0.23333333333333334\n",
      "The accuracy for each is [0.16666666666666666, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 24/50 was 1.6085613586685874\n",
      "The total balanced accuracy for validation was 0.24\n",
      "The validation loss was :   24/50 was 1.6083674530188243\n",
      "The unbalanced validation accuracy is 0.24\n",
      "The accuracy for each is [0.2, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 25/50 was 1.6085248589515686\n",
      "The total balanced accuracy for validation was 0.36333333333333334\n",
      "The validation loss was :   25/50 was 1.6083324694633483\n",
      "The unbalanced validation accuracy is 0.36333333333333334\n",
      "The accuracy for each is [0.8166666666666667, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 26/50 was 1.6084886680949817\n",
      "The total balanced accuracy for validation was 0.4\n",
      "The validation loss was :   26/50 was 1.6082979047298431\n",
      "The unbalanced validation accuracy is 0.4\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 27/50 was 1.608452628959309\n",
      "The total balanced accuracy for validation was 0.39333333333333337\n",
      "The validation loss was :   27/50 was 1.6082636884848276\n",
      "The unbalanced validation accuracy is 0.3933333333333333\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.9666666666666667, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 28/50 was 1.608416411009702\n",
      "The total balanced accuracy for validation was 0.39\n",
      "The validation loss was :   28/50 was 1.6082297825813294\n",
      "The unbalanced validation accuracy is 0.39\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.95, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 29/50 was 1.6083803122693843\n",
      "The total balanced accuracy for validation was 0.39\n",
      "The validation loss was :   29/50 was 1.6081955389181772\n",
      "The unbalanced validation accuracy is 0.39\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.95, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 30/50 was 1.6083444519476457\n",
      "The total balanced accuracy for validation was 0.39\n",
      "The validation loss was :   30/50 was 1.6081614939371744\n",
      "The unbalanced validation accuracy is 0.39\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.95, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 31/50 was 1.6083083152770996\n",
      "The total balanced accuracy for validation was 0.39\n",
      "The validation loss was :   31/50 was 1.6081275169054667\n",
      "The unbalanced validation accuracy is 0.39\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.95, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 32/50 was 1.608272379094904\n",
      "The total balanced accuracy for validation was 0.3833333333333333\n",
      "The validation loss was :   32/50 was 1.608093692859014\n",
      "The unbalanced validation accuracy is 0.38333333333333336\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.9166666666666666, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 33/50 was 1.6082364970987493\n",
      "The total balanced accuracy for validation was 0.3866666666666667\n",
      "The validation loss was :   33/50 was 1.6080606853961945\n",
      "The unbalanced validation accuracy is 0.38666666666666666\n",
      "The accuracy for each is [1.0, 0.03333333333333333, 0.0, 0.9, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 34/50 was 1.6081995205445723\n",
      "The total balanced accuracy for validation was 0.38666666666666666\n",
      "The validation loss was :   34/50 was 1.608028959830602\n",
      "The unbalanced validation accuracy is 0.38666666666666666\n",
      "The accuracy for each is [1.0, 0.05, 0.0, 0.8833333333333333, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 35/50 was 1.608161742036993\n",
      "The total balanced accuracy for validation was 0.38\n",
      "The validation loss was :   35/50 was 1.6079971543947855\n",
      "The unbalanced validation accuracy is 0.38\n",
      "The accuracy for each is [1.0, 0.11666666666666667, 0.0, 0.7833333333333333, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 36/50 was 1.6081236600875854\n",
      "The total balanced accuracy for validation was 0.39\n",
      "The validation loss was :   36/50 was 1.6079644231001535\n",
      "The unbalanced validation accuracy is 0.39\n",
      "The accuracy for each is [1.0, 0.25, 0.0, 0.7, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 37/50 was 1.6080857406963\n",
      "The total balanced accuracy for validation was 0.37333333333333335\n",
      "The validation loss was :   37/50 was 1.6079312682151794\n",
      "The unbalanced validation accuracy is 0.37333333333333335\n",
      "The accuracy for each is [1.0, 0.31666666666666665, 0.0, 0.55, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 38/50 was 1.6080478917468677\n",
      "The total balanced accuracy for validation was 0.3466666666666666\n",
      "The validation loss was :   38/50 was 1.6078977886835735\n",
      "The unbalanced validation accuracy is 0.3466666666666667\n",
      "The accuracy for each is [0.9833333333333333, 0.36666666666666664, 0.0, 0.38333333333333336, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 39/50 was 1.6080099994486028\n",
      "The total balanced accuracy for validation was 0.31\n",
      "The validation loss was :   39/50 was 1.6078632521629332\n",
      "The unbalanced validation accuracy is 0.31\n",
      "The accuracy for each is [0.8666666666666667, 0.45, 0.0, 0.23333333333333334, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 40/50 was 1.6079720638015054\n",
      "The total balanced accuracy for validation was 0.26\n",
      "The validation loss was :   40/50 was 1.6078280635674795\n",
      "The unbalanced validation accuracy is 0.26\n",
      "The accuracy for each is [0.6333333333333333, 0.48333333333333334, 0.0, 0.18333333333333332, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 41/50 was 1.6079339547590776\n",
      "The total balanced accuracy for validation was 0.18\n",
      "The validation loss was :   41/50 was 1.6077930172284445\n",
      "The unbalanced validation accuracy is 0.18\n",
      "The accuracy for each is [0.25, 0.5166666666666667, 0.0, 0.13333333333333333, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 42/50 was 1.607895097949288\n",
      "The total balanced accuracy for validation was 0.14666666666666667\n",
      "The validation loss was :   42/50 was 1.6077563083171844\n",
      "The unbalanced validation accuracy is 0.14666666666666667\n",
      "The accuracy for each is [0.05, 0.5666666666666667, 0.0, 0.11666666666666667, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 43/50 was 1.6078562519767068\n",
      "The total balanced accuracy for validation was 0.13666666666666666\n",
      "The validation loss was :   43/50 was 1.607718379497528\n",
      "The unbalanced validation accuracy is 0.13666666666666666\n",
      "The accuracy for each is [0.0, 0.6166666666666667, 0.0, 0.06666666666666667, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 44/50 was 1.6078173084692522\n",
      "The total balanced accuracy for validation was 0.14\n",
      "The validation loss was :   44/50 was 1.607679607073466\n",
      "The unbalanced validation accuracy is 0.14\n",
      "The accuracy for each is [0.0, 0.65, 0.0, 0.05, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 45/50 was 1.607777936892076\n",
      "The total balanced accuracy for validation was 0.15666666666666668\n",
      "The validation loss was :   45/50 was 1.6076398273309072\n",
      "The unbalanced validation accuracy is 0.15666666666666668\n",
      "The accuracy for each is [0.0, 0.7333333333333333, 0.0, 0.05, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 46/50 was 1.6077381535009905\n",
      "The total balanced accuracy for validation was 0.16666666666666669\n",
      "The validation loss was :   46/50 was 1.6075996987024943\n",
      "The unbalanced validation accuracy is 0.16666666666666666\n",
      "The accuracy for each is [0.0, 0.7833333333333333, 0.0, 0.05, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 47/50 was 1.607697757807645\n",
      "The total balanced accuracy for validation was 0.18333333333333335\n",
      "The validation loss was :   47/50 was 1.6075586942831674\n",
      "The unbalanced validation accuracy is 0.18333333333333332\n",
      "The accuracy for each is [0.0, 0.8666666666666667, 0.0, 0.05, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 48/50 was 1.6076569936492227\n",
      "The total balanced accuracy for validation was 0.19\n",
      "The validation loss was :   48/50 was 1.6075169424215952\n",
      "The unbalanced validation accuracy is 0.19\n",
      "The accuracy for each is [0.0, 0.9, 0.0, 0.05, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 49/50 was 1.6076155575838955\n",
      "The total balanced accuracy for validation was 0.19666666666666666\n",
      "The validation loss was :   49/50 was 1.6074744367599487\n",
      "The unbalanced validation accuracy is 0.19666666666666666\n",
      "The accuracy for each is [0.0, 0.95, 0.0, 0.03333333333333333, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 50/50 was 1.6075732653791255\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   50/50 was 1.6074309825897217\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.9666666666666667, 0.0, 0.03333333333333333, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train13 = trainer(\n",
    "    CNNinspired,\n",
    "    torch.cat((train1, train3), dim=0),\n",
    "    labels1 + labels3,\n",
    "    None,\n",
    "    train2,\n",
    "    labels2,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/50 was 1.6099638513156347\n",
      "The total balanced accuracy for validation was 0.19745222929936307\n",
      "The validation loss was :   1/50 was 1.6098371683412296\n",
      "The unbalanced validation accuracy is 0.19745222929936307\n",
      "The accuracy for each is [0.0, 0.006369426751592357, 0.0, 0.9808917197452229, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 2/50 was 1.6098855478422982\n",
      "The total balanced accuracy for validation was 0.19745222929936307\n",
      "The validation loss was :   2/50 was 1.609778178573414\n",
      "The unbalanced validation accuracy is 0.19745222929936307\n",
      "The accuracy for each is [0.0, 0.006369426751592357, 0.0, 0.9808917197452229, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 3/50 was 1.6098272715296065\n",
      "The total balanced accuracy for validation was 0.19745222929936307\n",
      "The validation loss was :   3/50 was 1.609735098158478\n",
      "The unbalanced validation accuracy is 0.19745222929936307\n",
      "The accuracy for each is [0.0, 0.0, 0.006369426751592357, 0.9808917197452229, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 4/50 was 1.6097863912582397\n",
      "The total balanced accuracy for validation was 0.19745222929936307\n",
      "The validation loss was :   4/50 was 1.6097056262812037\n",
      "The unbalanced validation accuracy is 0.19745222929936307\n",
      "The accuracy for each is [0.0, 0.0, 0.006369426751592357, 0.9808917197452229, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 5/50 was 1.6097555330821447\n",
      "The total balanced accuracy for validation was 0.19872611464968154\n",
      "The validation loss was :   5/50 was 1.6096816618731067\n",
      "The unbalanced validation accuracy is 0.19872611464968154\n",
      "The accuracy for each is [0.0, 0.0, 0.012738853503184714, 0.9808917197452229, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 6/50 was 1.6097296987261092\n",
      "The total balanced accuracy for validation was 0.2\n",
      "The validation loss was :   6/50 was 1.6096599094427315\n",
      "The unbalanced validation accuracy is 0.2\n",
      "The accuracy for each is [0.0, 0.0, 0.01910828025477707, 0.9808917197452229, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 7/50 was 1.6097055758748735\n",
      "The total balanced accuracy for validation was 0.20127388535031848\n",
      "The validation loss was :   7/50 was 1.6096399194875342\n",
      "The unbalanced validation accuracy is 0.20127388535031848\n",
      "The accuracy for each is [0.0, 0.006369426751592357, 0.01910828025477707, 0.9808917197452229, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 8/50 was 1.6096834880965096\n",
      "The total balanced accuracy for validation was 0.20254777070063695\n",
      "The validation loss was :   8/50 was 1.6096216128889922\n",
      "The unbalanced validation accuracy is 0.20254777070063695\n",
      "The accuracy for each is [0.0, 0.0, 0.03184713375796178, 0.9808917197452229, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 9/50 was 1.6096619963645935\n",
      "The total balanced accuracy for validation was 0.20382165605095542\n",
      "The validation loss was :   9/50 was 1.60960396824369\n",
      "The unbalanced validation accuracy is 0.20382165605095542\n",
      "The accuracy for each is [0.0, 0.0, 0.044585987261146494, 0.9745222929936306, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 10/50 was 1.609640998499734\n",
      "The total balanced accuracy for validation was 0.2050955414012739\n",
      "The validation loss was :   10/50 was 1.609587152140915\n",
      "The unbalanced validation accuracy is 0.2050955414012739\n",
      "The accuracy for each is [0.0, 0.0, 0.05732484076433121, 0.9681528662420382, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 11/50 was 1.6096202731132507\n",
      "The total balanced accuracy for validation was 0.20764331210191084\n",
      "The validation loss was :   11/50 was 1.6095706142437687\n",
      "The unbalanced validation accuracy is 0.20764331210191084\n",
      "The accuracy for each is [0.0, 0.0, 0.06369426751592357, 0.9745222929936306, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 12/50 was 1.6096004673412867\n",
      "The total balanced accuracy for validation was 0.21273885350318472\n",
      "The validation loss was :   12/50 was 1.6095544881881423\n",
      "The unbalanced validation accuracy is 0.21273885350318472\n",
      "The accuracy for each is [0.0, 0.0, 0.09554140127388536, 0.9681528662420382, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 13/50 was 1.6095809510775976\n",
      "The total balanced accuracy for validation was 0.21656050955414013\n",
      "The validation loss was :   13/50 was 1.609538599943659\n",
      "The unbalanced validation accuracy is 0.21656050955414013\n",
      "The accuracy for each is [0.0, 0.0, 0.12101910828025478, 0.9617834394904459, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 14/50 was 1.6095614262989588\n",
      "The total balanced accuracy for validation was 0.2178343949044586\n",
      "The validation loss was :   14/50 was 1.609522397199254\n",
      "The unbalanced validation accuracy is 0.2178343949044586\n",
      "The accuracy for each is [0.0, 0.0, 0.14012738853503184, 0.9490445859872612, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 15/50 was 1.6095419100352697\n",
      "The total balanced accuracy for validation was 0.2178343949044586\n",
      "The validation loss was :   15/50 was 1.6095061724352988\n",
      "The unbalanced validation accuracy is 0.2178343949044586\n",
      "The accuracy for each is [0.0, 0.0, 0.15286624203821655, 0.9363057324840764, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 16/50 was 1.6095223341669356\n",
      "The total balanced accuracy for validation was 0.2178343949044586\n",
      "The validation loss was :   16/50 was 1.60948989816532\n",
      "The unbalanced validation accuracy is 0.2178343949044586\n",
      "The accuracy for each is [0.0, 0.0, 0.1592356687898089, 0.9299363057324841, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 17/50 was 1.609502843448094\n",
      "The total balanced accuracy for validation was 0.22420382165605096\n",
      "The validation loss was :   17/50 was 1.6094738024814872\n",
      "The unbalanced validation accuracy is 0.22420382165605096\n",
      "The accuracy for each is [0.0, 0.0, 0.1910828025477707, 0.9299363057324841, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 18/50 was 1.6094834804534912\n",
      "The total balanced accuracy for validation was 0.22929936305732485\n",
      "The validation loss was :   18/50 was 1.609457559038879\n",
      "The unbalanced validation accuracy is 0.22929936305732485\n",
      "The accuracy for each is [0.0, 0.0, 0.22929936305732485, 0.9171974522292994, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 19/50 was 1.6094644580568587\n",
      "The total balanced accuracy for validation was 0.2356687898089172\n",
      "The validation loss was :   19/50 was 1.6094411473365346\n",
      "The unbalanced validation accuracy is 0.2356687898089172\n",
      "The accuracy for each is [0.0, 0.0, 0.267515923566879, 0.910828025477707, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 20/50 was 1.609445605959211\n",
      "The total balanced accuracy for validation was 0.23439490445859873\n",
      "The validation loss was :   20/50 was 1.609424764942971\n",
      "The unbalanced validation accuracy is 0.23439490445859873\n",
      "The accuracy for each is [0.0, 0.0, 0.2802547770700637, 0.89171974522293, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 21/50 was 1.6094267112868172\n",
      "The total balanced accuracy for validation was 0.2394904458598726\n",
      "The validation loss was :   21/50 was 1.609408398494599\n",
      "The unbalanced validation accuracy is 0.2394904458598726\n",
      "The accuracy for each is [0.0, 0.0, 0.3248407643312102, 0.8726114649681529, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 22/50 was 1.6094078506742204\n",
      "The total balanced accuracy for validation was 0.24203821656050956\n",
      "The validation loss was :   22/50 was 1.6093919997002668\n",
      "The unbalanced validation accuracy is 0.24203821656050956\n",
      "The accuracy for each is [0.0, 0.0, 0.34394904458598724, 0.8662420382165605, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 23/50 was 1.6093892114503043\n",
      "The total balanced accuracy for validation was 0.2484076433121019\n",
      "The validation loss was :   23/50 was 1.609375589364653\n",
      "The unbalanced validation accuracy is 0.2484076433121019\n",
      "The accuracy for each is [0.0, 0.0, 0.3821656050955414, 0.8598726114649682, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 24/50 was 1.6093703252928597\n",
      "The total balanced accuracy for validation was 0.25605095541401274\n",
      "The validation loss was :   24/50 was 1.6093593656637106\n",
      "The unbalanced validation accuracy is 0.25605095541401274\n",
      "The accuracy for each is [0.0, 0.0, 0.43312101910828027, 0.8471337579617835, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 25/50 was 1.6093516179493494\n",
      "The total balanced accuracy for validation was 0.2535031847133758\n",
      "The validation loss was :   25/50 was 1.6093430355096319\n",
      "The unbalanced validation accuracy is 0.2535031847133758\n",
      "The accuracy for each is [0.0, 0.0, 0.445859872611465, 0.821656050955414, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 26/50 was 1.6093328510011946\n",
      "The total balanced accuracy for validation was 0.24585987261146497\n",
      "The validation loss was :   26/50 was 1.6093267176561294\n",
      "The unbalanced validation accuracy is 0.24585987261146497\n",
      "The accuracy for each is [0.0, 0.0, 0.46496815286624205, 0.7643312101910829, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 27/50 was 1.6093141351427351\n",
      "The total balanced accuracy for validation was 0.24331210191082803\n",
      "The validation loss was :   27/50 was 1.6093103141541694\n",
      "The unbalanced validation accuracy is 0.24331210191082803\n",
      "The accuracy for each is [0.0, 0.0, 0.4968152866242038, 0.7197452229299363, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 28/50 was 1.6092953767095293\n",
      "The total balanced accuracy for validation was 0.2445859872611465\n",
      "The validation loss was :   28/50 was 1.6092939108040683\n",
      "The unbalanced validation accuracy is 0.2445859872611465\n",
      "The accuracy for each is [0.0, 0.0, 0.5286624203821656, 0.6942675159235668, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 29/50 was 1.6092766267912728\n",
      "The total balanced accuracy for validation was 0.2394904458598726\n",
      "The validation loss was :   29/50 was 1.6092774345616627\n",
      "The unbalanced validation accuracy is 0.2394904458598726\n",
      "The accuracy for each is [0.0, 0.0, 0.5414012738853503, 0.6560509554140127, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 30/50 was 1.6092577746936254\n",
      "The total balanced accuracy for validation was 0.24713375796178344\n",
      "The validation loss was :   30/50 was 1.6092608908938755\n",
      "The unbalanced validation accuracy is 0.24713375796178344\n",
      "The accuracy for each is [0.0, 0.0, 0.5923566878980892, 0.643312101910828, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 31/50 was 1.6092388885361808\n",
      "The total balanced accuracy for validation was 0.24585987261146497\n",
      "The validation loss was :   31/50 was 1.6092442507956437\n",
      "The unbalanced validation accuracy is 0.24585987261146497\n",
      "The accuracy for each is [0.0, 0.0, 0.6050955414012739, 0.6242038216560509, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 32/50 was 1.6092199853488378\n",
      "The total balanced accuracy for validation was 0.2445859872611465\n",
      "The validation loss was :   32/50 was 1.6092276605071536\n",
      "The unbalanced validation accuracy is 0.2445859872611465\n",
      "The accuracy for each is [0.0, 0.0, 0.6305732484076433, 0.5923566878980892, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 33/50 was 1.6092010140419006\n",
      "The total balanced accuracy for validation was 0.2445859872611465\n",
      "The validation loss was :   33/50 was 1.6092110043118715\n",
      "The unbalanced validation accuracy is 0.2445859872611465\n",
      "The accuracy for each is [0.0, 0.0, 0.6624203821656051, 0.5605095541401274, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 34/50 was 1.6091820342200143\n",
      "The total balanced accuracy for validation was 0.24076433121019108\n",
      "The validation loss was :   34/50 was 1.6091942943585147\n",
      "The unbalanced validation accuracy is 0.24076433121019108\n",
      "The accuracy for each is [0.0, 0.0, 0.6687898089171974, 0.535031847133758, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 35/50 was 1.6091629777635847\n",
      "The total balanced accuracy for validation was 0.24331210191082803\n",
      "The validation loss was :   35/50 was 1.6091774849375342\n",
      "The unbalanced validation accuracy is 0.24331210191082803\n",
      "The accuracy for each is [0.0, 0.0, 0.7070063694267515, 0.5095541401273885, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 36/50 was 1.6091438957623072\n",
      "The total balanced accuracy for validation was 0.24203821656050956\n",
      "The validation loss was :   36/50 was 1.609160660330657\n",
      "The unbalanced validation accuracy is 0.24203821656050956\n",
      "The accuracy for each is [0.0, 0.0, 0.7133757961783439, 0.4968152866242038, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 37/50 was 1.609124779701233\n",
      "The total balanced accuracy for validation was 0.24331210191082803\n",
      "The validation loss was :   37/50 was 1.6091437493160272\n",
      "The unbalanced validation accuracy is 0.24331210191082803\n",
      "The accuracy for each is [0.012738853503184714, 0.0, 0.7261146496815286, 0.47770700636942676, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 38/50 was 1.609105442251478\n",
      "The total balanced accuracy for validation was 0.2484076433121019\n",
      "The validation loss was :   38/50 was 1.6091267802912719\n",
      "The unbalanced validation accuracy is 0.2484076433121019\n",
      "The accuracy for each is [0.03184713375796178, 0.0, 0.7388535031847133, 0.4713375796178344, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 39/50 was 1.6090861814362662\n",
      "The total balanced accuracy for validation was 0.25095541401273885\n",
      "The validation loss was :   39/50 was 1.6091097493080577\n",
      "The unbalanced validation accuracy is 0.25095541401273885\n",
      "The accuracy for each is [0.044585987261146494, 0.0, 0.7452229299363057, 0.46496815286624205, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 40/50 was 1.6090667588370187\n",
      "The total balanced accuracy for validation was 0.2535031847133758\n",
      "The validation loss was :   40/50 was 1.6090926673002304\n",
      "The unbalanced validation accuracy is 0.2535031847133758\n",
      "The accuracy for each is [0.07006369426751592, 0.0, 0.7452229299363057, 0.45222929936305734, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 41/50 was 1.609047259603228\n",
      "The total balanced accuracy for validation was 0.25732484076433126\n",
      "The validation loss was :   41/50 was 1.6090755222709316\n",
      "The unbalanced validation accuracy is 0.2573248407643312\n",
      "The accuracy for each is [0.10191082802547771, 0.0, 0.7579617834394905, 0.4267515923566879, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 42/50 was 1.60902772630964\n",
      "The total balanced accuracy for validation was 0.26369426751592356\n",
      "The validation loss was :   42/50 was 1.609058314675738\n",
      "The unbalanced validation accuracy is 0.26369426751592356\n",
      "The accuracy for each is [0.1592356687898089, 0.0, 0.7515923566878981, 0.40764331210191085, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 43/50 was 1.609008048261915\n",
      "The total balanced accuracy for validation was 0.27388535031847133\n",
      "The validation loss was :   43/50 was 1.6090410089796516\n",
      "The unbalanced validation accuracy is 0.27388535031847133\n",
      "The accuracy for each is [0.2356687898089172, 0.0, 0.7388535031847133, 0.39490445859872614, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 44/50 was 1.6089884213038854\n",
      "The total balanced accuracy for validation was 0.2968152866242038\n",
      "The validation loss was :   44/50 was 1.6090236155090818\n",
      "The unbalanced validation accuracy is 0.2968152866242038\n",
      "The accuracy for each is [0.36942675159235666, 0.0, 0.7388535031847133, 0.37579617834394907, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 45/50 was 1.6089684963226318\n",
      "The total balanced accuracy for validation was 0.3057324840764331\n",
      "The validation loss was :   45/50 was 1.6090061415532593\n",
      "The unbalanced validation accuracy is 0.3057324840764331\n",
      "The accuracy for each is [0.46496815286624205, 0.0, 0.6942675159235668, 0.36942675159235666, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 46/50 was 1.6089485032217843\n",
      "The total balanced accuracy for validation was 0.3146496815286624\n",
      "The validation loss was :   46/50 was 1.6089885350245579\n",
      "The unbalanced validation accuracy is 0.3146496815286624\n",
      "The accuracy for each is [0.5796178343949044, 0.0, 0.6496815286624203, 0.34394904458598724, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 47/50 was 1.6089283909116472\n",
      "The total balanced accuracy for validation was 0.32993630573248406\n",
      "The validation loss was :   47/50 was 1.6089708477068858\n",
      "The unbalanced validation accuracy is 0.32993630573248406\n",
      "The accuracy for each is [0.7261146496815286, 0.0, 0.5859872611464968, 0.3375796178343949, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 48/50 was 1.6089082189968653\n",
      "The total balanced accuracy for validation was 0.31974522292993635\n",
      "The validation loss was :   48/50 was 1.6089529004066614\n",
      "The unbalanced validation accuracy is 0.3197452229299363\n",
      "The accuracy for each is [0.8089171974522293, 0.0, 0.47770700636942676, 0.31210191082802546, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 49/50 was 1.6088878512382507\n",
      "The total balanced accuracy for validation was 0.32101910828025476\n",
      "The validation loss was :   49/50 was 1.6089349031448363\n",
      "The unbalanced validation accuracy is 0.32101910828025476\n",
      "The accuracy for each is [0.910828025477707, 0.0, 0.40764331210191085, 0.28662420382165604, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 50/50 was 1.608867543084281\n",
      "The total balanced accuracy for validation was 0.310828025477707\n",
      "The validation loss was :   50/50 was 1.6089167833328246\n",
      "The unbalanced validation accuracy is 0.310828025477707\n",
      "The accuracy for each is [0.9617834394904459, 0.0, 0.3248407643312102, 0.267515923566879, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train23 = trainer(\n",
    "    CNNinspired,\n",
    "    torch.cat((train3, train2), dim=0),\n",
    "    labels3 + labels2,\n",
    "    None,\n",
    "    train1,\n",
    "    labels1,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy of all three models on all data:  0.22634730538922154\n"
     ]
    }
   ],
   "source": [
    "        acc = getTotalAccuracy(train12, train23, train13, \n",
    "                       torch.cat((train1, train2, train3), dim=0),\n",
    "                       labels1 + labels2 + labels3)\n",
    "print('Average accuracy of all three models on all data: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-75557cec9d0a>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-75557cec9d0a>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    tripList.append([ma, {'drop1: d'} r])\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# def cfvalidation(tripList, module, x1, y1, x2, y2, x3, y3, **trainKwargs):\n",
    "#         for (modelArgs, modelKwargs, lr) in tripList:\n",
    "from normalizer import cfvalidation\n",
    "ns = [1,3,5,7]\n",
    "hls = [30, 128, 256]\n",
    "margs = []\n",
    "for n in ns:\n",
    "    for h in hls:\n",
    "        margs.append([n,h])\n",
    "lrs = [10**i for i in range(0,-10, -1)]\n",
    "drs = [0, .05, .25, .45, .5]\n",
    "tripList = []\n",
    "for ma in margs:\n",
    "    for r in lrs:\n",
    "        for d in drs:\n",
    "            tripList.append([ma, {'drop1: d'} r])\n",
    "lossArgs, quickArgs = cfvalidation(tripList, CNNinspired, train1, labels1, train2, labels2, train3, labels3, epochs=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model creation for testing ##\n",
    "\n",
    "Once acceptable hyperparameters have been established, run this code to train on all the data and print out a CSV that predicts from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train123 = trainer(\n",
    "    CNNinspired,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# def tester(model, pathToWrite=None):\n",
    "#     if pathToWrite is None:\n",
    "#         pathToWrite = f'results/submission{datetime.now().strftime(\"%d_%H:%M\")}.csv'\n",
    "#     # Get test data\n",
    "#     test, ids, _ = getDataFromJSON(path='data/test_4_5_data.json', test=True, device=device)\n",
    "#     # get our guesses from the network\n",
    "#     guesses = torch.argmax(model(test))\n",
    "#     assert len(ids) == guesses.shape\n",
    "#     # Open a file to write to\n",
    "#     file = open(pathToWrite, mode='w')\n",
    "#     print('Id,Label', file=file)\n",
    "#     for i in range(len(ids)):\n",
    "#         print(ids[i], guesses[i], sep=',', file=file)\n",
    "    file.close()\n",
    "\n",
    "tester(train123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "acc = \n",
    "PATH = f'savedModels/lr{lr}acc{acc}time{datetime.now().strftime(\"%d_%H:%M\")}.pth'\n",
    "torch.save(newModel.state_dict(), PATH)\n",
    "print('REMEMBER TO DELETE YOUR ACCURACY SO THE NEXT PERSON REMEMBERS TO WRITE THEIRS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
