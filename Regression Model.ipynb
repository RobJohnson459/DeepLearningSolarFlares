{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robjohnson/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from normalizer import subSample, getDataFromJSON, trainer, getTotalAccuracy\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # Change this to cuda for GPU enabled computers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition1_data.json\n",
      "Now loading event 1/785\n",
      "Now loading event 101/785\n",
      "Now loading event 201/785\n",
      "Now loading event 301/785\n",
      "Now loading event 401/785\n",
      "Now loading event 501/785\n",
      "Now loading event 601/785\n",
      "Now loading event 701/785\n",
      "785 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "# This file has 77270 data points. 71633 do not have NAN values.\n",
    "# %time train1, labels1, weights1 = getDataFromJSON(path=\"data/train_partition1_data.json\", earlyStop=-1)\n",
    "train1, labels1 = subSample(\"data/train_partition1_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition2_data.json\n",
      "Now loading event 1/300\n",
      "Now loading event 101/300\n",
      "Now loading event 201/300\n",
      "300 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "# This file has 93767 data points. 82425 of them do not have NAN values.  \n",
    "# %time train2, labels2, weights2 = getDataFromJSON(path=\"data/train_partition2_data.json\", earlyStop=-1)\n",
    "train2, labels2 = subSample(\"data/train_partition2_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading data/train_partition3_data.json\n",
      "Now loading event 1/585\n",
      "Now loading event 101/585\n",
      "Now loading event 201/585\n",
      "Now loading event 301/585\n",
      "Now loading event 401/585\n",
      "Now loading event 501/585\n",
      "585 lines loaded.\n"
     ]
    }
   ],
   "source": [
    "# This file has 42986 data points. 37759 of them do not have NAN values.  \n",
    "# %time train3, labels3, weights3 = getDataFromJSON(path=\"data/train_partition3_data.json\", earlyStop=-1)\n",
    "train3, labels3 = subSample(\"data/train_partition3_data.json\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0693, 0.0694, 0.0694, 0.0696, 0.0693, 0.0697, 0.0696, 0.0689, 0.0690,\n",
       "        0.0689, 0.0688, 0.0685, 0.0689, 0.0692, 0.0696, 0.0696, 0.0695, 0.0693,\n",
       "        0.0693, 0.0688, 0.0680, 0.0671, 0.0669, 0.0667, 0.0663, 0.0664, 0.0664,\n",
       "        0.0666, 0.0659, 0.0657, 0.0651, 0.0649, 0.0650, 0.0663, 0.0667, 0.0668,\n",
       "        0.0670, 0.0674, 0.0678, 0.0681, 0.0678, 0.0678, 0.0679, 0.0680, 0.0682,\n",
       "        0.0684, 0.0690, 0.0689, 0.0689, 0.0693, 0.0691, 0.0692, 0.0697, 0.0699,\n",
       "        0.0698, 0.0699, 0.0700, 0.0698, 0.0694, 0.0692])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0979, 0.0984, 0.0984, 0.0984, 0.0979, 0.1002, 0.1009, 0.0993, 0.0991,\n",
       "        0.0988, 0.0982, 0.0994, 0.0994, 0.1009, 0.0996, 0.0983, 0.0981, 0.0979,\n",
       "        0.0981, 0.0959, 0.0930, 0.0925, 0.0933, 0.0921, 0.0917, 0.0936, 0.0929,\n",
       "        0.0957, 0.0949, 0.0963, 0.0969, 0.0948, 0.0961, 0.1017, 0.1055, 0.1060,\n",
       "        0.1081, 0.1079, 0.1068, 0.1091, 0.1102, 0.1115, 0.1105, 0.1104, 0.1104,\n",
       "        0.1123, 0.1163, 0.1141, 0.1147, 0.1149, 0.1135, 0.1131, 0.1144, 0.1126,\n",
       "        0.1127, 0.1134, 0.1130, 0.1128, 0.1103, 0.1084])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network. Make sure to end with nn.Softmax activation\n",
    "import torch.nn as nn\n",
    "# from skorch import NeuralNet\n",
    "\n",
    "class logRegWithHidden(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, num_classes=5, drop1=.5, input_size=1980):\n",
    "        super().__init__() \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layerout = nn.Linear(hidden_size2, num_classes)\n",
    "        #Define a RELU Activation unit\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.smax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(p=drop1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Forward Propagate through the layers as defined above\n",
    "        y = self.drop(x.reshape(-1, 1980))\n",
    "        y = self.drop(self.relu(self.layer1(y)))\n",
    "        y = self.relu(self.layer2(y))\n",
    "        y = self.layerout(y)\n",
    "        y = self.smax(y)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust hyper parameters with 3 fold validation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelArgs = [4096*4, 2048*4]\n",
    "modelKwargs = {'drop1':.25}\n",
    "trainKwargs = {'epochs':50, 'lr':0.0001}\n",
    "# Attempted learning rates: \n",
    "# 0.0001 : one in a thousand change\n",
    "# 0.00001 : one in TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 1/50 was 1.6095042088452507\n",
      "The total balanced accuracy for validation was 0.2341880341880342\n",
      "The validation loss was :   1/50 was 1.6090488236174625\n",
      "The unbalanced validation accuracy is 0.2341880341880342\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.17094017094017094, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 2/50 was 1.609286623842576\n",
      "The total balanced accuracy for validation was 0.23247863247863249\n",
      "The validation loss was :   2/50 was 1.6089208731284508\n",
      "The unbalanced validation accuracy is 0.23247863247863249\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.1623931623931624, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 3/50 was 1.6093182844274185\n",
      "The total balanced accuracy for validation was 0.22905982905982905\n",
      "The validation loss was :   3/50 was 1.6087923003058149\n",
      "The unbalanced validation accuracy is 0.22905982905982905\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.1452991452991453, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 4/50 was 1.609229235088124\n",
      "The total balanced accuracy for validation was 0.22735042735042735\n",
      "The validation loss was :   4/50 was 1.608664463320349\n",
      "The unbalanced validation accuracy is 0.22735042735042735\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.13675213675213677, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 5/50 was 1.6086225439520443\n",
      "The total balanced accuracy for validation was 0.22051282051282053\n",
      "The validation loss was :   5/50 was 1.6085358719540457\n",
      "The unbalanced validation accuracy is 0.2205128205128205\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.10256410256410256, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 6/50 was 1.6089143262189978\n",
      "The total balanced accuracy for validation was 0.21880341880341883\n",
      "The validation loss was :   6/50 was 1.6084083685508141\n",
      "The unbalanced validation accuracy is 0.2188034188034188\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.09401709401709402, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 7/50 was 1.6087145174250883\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   7/50 was 1.6082815098966288\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 8/50 was 1.6082580580430872\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   8/50 was 1.6081551081094987\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 9/50 was 1.6084783778471106\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   9/50 was 1.6080286998015183\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 10/50 was 1.6082381150301766\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   10/50 was 1.6079027662929306\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 11/50 was 1.6081462677787333\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   11/50 was 1.6077772823154417\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 12/50 was 1.608229209395016\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   12/50 was 1.607651880867461\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 13/50 was 1.6078615819706636\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   13/50 was 1.6075262628049931\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 14/50 was 1.607709849581999\n",
      "The total balanced accuracy for validation was 0.21709401709401707\n",
      "The validation loss was :   14/50 was 1.6074020522272485\n",
      "The unbalanced validation accuracy is 0.2170940170940171\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.08547008547008547, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 15/50 was 1.6077415031545303\n",
      "The total balanced accuracy for validation was 0.21538461538461537\n",
      "The validation loss was :   15/50 was 1.6072772103497106\n",
      "The unbalanced validation accuracy is 0.2153846153846154\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.07692307692307693, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 16/50 was 1.607611522955053\n",
      "The total balanced accuracy for validation was 0.21538461538461537\n",
      "The validation loss was :   16/50 was 1.6071533914305205\n",
      "The unbalanced validation accuracy is 0.2153846153846154\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.07692307692307693, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 17/50 was 1.6078453554826624\n",
      "The total balanced accuracy for validation was 0.21538461538461537\n",
      "The validation loss was :   17/50 was 1.6070300793036436\n",
      "The unbalanced validation accuracy is 0.2153846153846154\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.07692307692307693, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 18/50 was 1.6072598345139448\n",
      "The total balanced accuracy for validation was 0.21367521367521367\n",
      "The validation loss was :   18/50 was 1.6069064564175075\n",
      "The unbalanced validation accuracy is 0.21367521367521367\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.06837606837606838, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 19/50 was 1.6073427621056051\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   19/50 was 1.6067821653480203\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 20/50 was 1.6072734804714428\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   20/50 was 1.6066587197474944\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 21/50 was 1.6074452470330631\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   21/50 was 1.6065362736710116\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 22/50 was 1.6068792202893425\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   22/50 was 1.6064133208022158\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 23/50 was 1.6067823241738712\n",
      "The total balanced accuracy for validation was 0.21196581196581196\n",
      "The validation loss was :   23/50 was 1.6062909393229037\n",
      "The unbalanced validation accuracy is 0.21196581196581196\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05982905982905983, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 24/50 was 1.6067255875643562\n",
      "The total balanced accuracy for validation was 0.21025641025641026\n",
      "The validation loss was :   24/50 was 1.6061693436060196\n",
      "The unbalanced validation accuracy is 0.21025641025641026\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05128205128205128, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss for epoch 25/50 was 1.6065998778623694\n",
      "The total balanced accuracy for validation was 0.21025641025641026\n",
      "The validation loss was :   25/50 was 1.6060477026507385\n",
      "The unbalanced validation accuracy is 0.21025641025641026\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05128205128205128, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 26/50 was 1.6062607484705307\n",
      "The total balanced accuracy for validation was 0.21025641025641026\n",
      "The validation loss was :   26/50 was 1.6059265540196346\n",
      "The unbalanced validation accuracy is 0.21025641025641026\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.05128205128205128, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 27/50 was 1.606649917714736\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   27/50 was 1.605805867146223\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 28/50 was 1.6061673865598791\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   28/50 was 1.6056839099297158\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 29/50 was 1.6060215304879581\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   29/50 was 1.6055622139547625\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 30/50 was 1.605934739112854\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   30/50 was 1.6054416931592501\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 31/50 was 1.6057410310296452\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   31/50 was 1.6053211609522502\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 32/50 was 1.6058657730326933\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   32/50 was 1.6052006766327427\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 33/50 was 1.605603246127858\n",
      "The total balanced accuracy for validation was 0.20854700854700856\n",
      "The validation loss was :   33/50 was 1.6050802793258276\n",
      "The unbalanced validation accuracy is 0.20854700854700856\n",
      "The accuracy for each is [1.0, 0.0, 0.0, 0.042735042735042736, 0.0]\n",
      "\n",
      "\n",
      "=============End Epoch==============\n",
      "\n",
      "\n",
      "The training loss for epoch 34/50 was 1.6052868857103235\n"
     ]
    }
   ],
   "source": [
    "train1Args = [logRegWithHidden, torch.cat((train1, train2), dim=0), labels1 + labels2, None, train3, labels3, None]\n",
    "%time train12 = trainer(*train1Args, *modelArgs, **trainKwargs, **modelKwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train13 = trainer(\n",
    "    logRegWithHidden,\n",
    "    torch.cat((train1, train3), dim=0),\n",
    "    labels1 + labels3,\n",
    "    None,\n",
    "    train2,\n",
    "    labels2,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train23 = trainer(\n",
    "    logRegWithHidden,\n",
    "    torch.cat((train3, train2), dim=0),\n",
    "    labels3 + labels2,\n",
    "    None,\n",
    "    train1,\n",
    "    labels1,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = getTotalAccuracy(train12, train23, train13, \n",
    "                       torch.cat((train1, train2, train3), dim=0),\n",
    "                      labels1 + labels2 + labels3)\n",
    "print('Average accuracy of all three models on all data: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model creation for testing ##\n",
    "\n",
    "Once acceptable hyperparameters have been established, run this code to train on all the data and print out a CSV that predicts from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train123 = trainer(\n",
    "    logRegWithHidden,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    torch.cat((train1, train2, train3), dim=0),\n",
    "    labels1 + labels2 + labels3,\n",
    "    None,\n",
    "    *modelArgs,\n",
    "    **trainKwargs,\n",
    "    **modelKwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def tester(model, pathToWrite=None):\n",
    "    if pathToWrite is None:\n",
    "        pathToWrite = f'results/submission{datetime.now().strftime(\"%d_%H:%M\")}.csv'\n",
    "    # Get test data\n",
    "    test, ids, _ = getDataFromJSON(path='data/test_4_5_data.json', test=True, device=device)\n",
    "    # get our guesses from the network\n",
    "    guesses = torch.argmax(model(test))\n",
    "    assert len(ids) == guesses.shape\n",
    "    # Open a file to write to\n",
    "    file = open(pathToWrite, mode='w')\n",
    "    print('Id,Label', file=file)\n",
    "    for i in range(len(ids)):\n",
    "        print(ids[i], guesses[i], sep=',', file=file)\n",
    "    file.close()\n",
    "\n",
    "tester(train123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "acc = \n",
    "PATH = f'savedModels/lr{lr}acc{acc}time{datetime.now().strftime(\"%d_%H:%M\")}.pth'\n",
    "torch.save(newModel.state_dict(), PATH)\n",
    "print('REMEMBER TO DELETE YOUR ACCURACY SO THE NEXT PERSON REMEMBERS TO WRITE THEIRS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
